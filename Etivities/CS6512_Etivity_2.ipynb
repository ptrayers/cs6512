{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29614d2c",
   "metadata": {
    "id": "29614d2c"
   },
   "source": [
    "<div>\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1vK33e_EqaHgBHcbRV_m38hx6IkG0blK_\" width=\"350\"/>\n",
    "</div>\n",
    "\n",
    "# **Artificial Intelligence - MSc**\n",
    "\n",
    "## CS6512 - AI & Data Science Ecosystems - Theory and Practice\n",
    "## SEM2 2022/3\n",
    "\n",
    "### CS6512 Etivity 2 - Implementing a Layer Detector for Cryptocurrency Rates with AWS\n",
    "\n",
    "### Instructor: Emil Vassev\n",
    "April 20th, 2023\n",
    "<br><br>\n",
    "Copyright (C) 2023 - All rights reserved, do not copy or distribute without permission of the author.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wRmf11FGLPB8",
   "metadata": {
    "id": "wRmf11FGLPB8"
   },
   "source": [
    "## Submission Info\n",
    "### Student Name: Paul\n",
    "### Student Surname: Trayers\n",
    "### Student ID: 8907021\n",
    "### Date of Final Submission: Apr 21 2024\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab7afe0",
   "metadata": {
    "id": "bab7afe0"
   },
   "source": [
    "## Task\n",
    "In this e-tivity, you will be granted with access to an AWS Academy Learner Lab, and asked to:\n",
    "<ol>\n",
    "<li>Follow the provided instructions to set up your AWS environment.</li>\n",
    "<li>Implement an Outlier Detector for cryptocurrency rates by using the outlier-detection algorithms covered in class:\n",
    "<ul>\n",
    "<li>Enhanced Dixon Q</li>\n",
    "<li>Mean & Standard Deviation</li>\n",
    "<li>Isolation Forest</li>\n",
    "<li>Boxplots Method</li>\n",
    "<li>DBSCAN Clustering Method</li>\n",
    "</ul></li>    \n",
    "</ol>\n",
    "\n",
    "Your outlier detector shall be implemented in Python and run on AWS SageMaker.\n",
    "\n",
    "### Implementation Subtasks\n",
    "This e-tivity has two distinct subtasks:\n",
    "<ol>\n",
    "    <li>Detecting outliers among cryptocurrency history rates</li>\n",
    "    <li>Detecting outliers among cryptocurrency live-exchange rates</li>\n",
    "</ol>    \n",
    "\n",
    "### Subtask #1: Detecting outliers among cryptocurrency history rates\n",
    "<ol>\n",
    "<li>Use the AWS SageMaker to open a Jupyter Notebook and implement your assignment there.</li>\n",
    "<li>Set up an S3 bucket, upload the **instrument_price.csv** file and use the provided interface to read from and write to this and othere files there.</li>\n",
    "<li>Implement an outlier detector that runs on the AWS SageMaker and:\n",
    "  <ul>\n",
    "    <li>loads csv data from the AWS S3 storage space and produces an outlier report</li>\n",
    "    <li>gets hystory rates from the marketplace CryptoCompare.com and produces an outlier report</li>\n",
    "  </ul>\n",
    "</li>\n",
    "</ol>\n",
    "\n",
    "### Subtask #2: Detecting outliers among cryptocurrency live-exchange rates\n",
    "<ol>\n",
    "<li>Implement a new feature of your Outlier Detector, so it will:\n",
    "  <ol>\n",
    "    <li>Get live-exchange cryptocurrency rates from the marketplace CryptoCompare.com on every 30 sec.</li>\n",
    "    <li>Store these cryptocurrency rates.</li>\n",
    "    <li>Detect outliers among these cryptocurrency rates.</li>\n",
    "  </ol>\n",
    "</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21386189",
   "metadata": {
    "id": "21386189"
   },
   "source": [
    "## Note\n",
    "<span style=\"color:blue\">You will be provided with:</span>\n",
    "  <ul>\n",
    "    <li><span style=\"color:blue\">implementation of the outlier-detection algorithms:</span>\n",
    "      <ul>  \n",
    "       <li>class DixonQEnhanced</li>\n",
    "       <li>class StandardDeviationMethod</li>\n",
    "       <li>class IsolationForestMethod</li>\n",
    "       <li>class BoxPlotsMethod</li>\n",
    "       <li>class DBScanClusteringMethod</li>\n",
    "      </ul>    \n",
    "    </li>\n",
    "    <li><span style=\"color:blue\">implementation of reading live-exchange rates from CryptoCompare.com:</span>\n",
    "      <ul>  \n",
    "       <li>class CryptoCompareReader</li>\n",
    "      </ul>  \n",
    "    </li>\n",
    "    <li><span style=\"color:blue\">a library making the communication with the s3 bucket transparent:</span>\n",
    "      <ul>  \n",
    "       <li>class S3Utils</li>\n",
    "      </ul>  \n",
    "    </li>\n",
    "    <li><span style=\"color:blue\">implementation of the structure of your code (class and methods) - you will need to follow this structure:</span>\n",
    "      <ul>  \n",
    "       <li>class CS6512Assignment2</li>\n",
    "      </ul>\n",
    "    </li>\n",
    "  </ul>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c491d2",
   "metadata": {
    "id": "31c491d2"
   },
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f69ede9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.34.93)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.93 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.34.93)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.93->boto3) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.93->boto3) (2.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.93->boto3) (1.16.0)\n",
      "Boto3 version: 1.34.93\n",
      "/home/ec2-user/anaconda3/envs/python3/bin/python\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "arn:aws:iam::960701162063:role/service-role/SageMaker-DataScientist\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3\n",
    "\n",
    "import boto3\n",
    "print(\"Boto3 version:\", boto3.__version__)\n",
    "\n",
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "print(role)  # role that SM will use to access AWS resources (S3, CloudWatch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ae108da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bucket_name = 'ptrayers-ul-cs6512'\n",
    "#AWS_S3_BUCKET = bucket_name\n",
    "\n",
    "#s3_client = S3Utils(AWS_S3_BUCKET)\n",
    "\n",
    "#df = s3_client.readCsvFileFromBucket('instrument_price.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b6978c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current region: eu-west-1\n",
      "bhf-solution-design-worshop\n",
      "budapest-recipes\n",
      "mokotow-pics\n",
      "ptrayers-bucket\n",
      "ptrayers-ul-cs6512\n",
      "sagemaker-eu-west-1-960701162063\n",
      "sagemaker-studio-960701162063-0i0o0jxf4n35\n",
      "\n",
      "ptrayers-ul-cs6512..\n",
      "data/\n",
      "instrument_price.csv\n",
      "outliers_output_phase_1.json\n",
      "outliers_output_phase_2.json\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "#AWS_ACCESS_KEY_ID = \"AKIA57LSAMJH4GSEFP3Z\"\n",
    "#AWS_SECRET_ACCESS_KEY = \"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\"\n",
    "\n",
    "session = boto3.session.Session()\n",
    "current_region = session.region_name\n",
    "print(\"Current region:\", current_region)\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "# List all buckets to test permissions\n",
    "for bucket in s3_client.list_buckets()['Buckets']:\n",
    "    print(bucket['Name'])\n",
    "    \n",
    "# Specify the bucket name\n",
    "bucket_name = 'ptrayers-ul-cs6512'\n",
    "\n",
    "# List all objects in the specified bucket\n",
    "def list_bucket_contents(bucket):\n",
    "    paginator = s3_client.get_paginator('list_objects_v2')\n",
    "    for page in paginator.paginate(Bucket=bucket):\n",
    "        for obj in page.get('Contents', []):\n",
    "            print(obj['Key'])\n",
    "\n",
    "# Call the function with your specific bucket name\n",
    "print(f\"\\n{bucket_name}..\")\n",
    "list_bucket_contents(bucket_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ee33d5",
   "metadata": {
    "id": "93ee33d5"
   },
   "source": [
    "### Libraries to Use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f88182",
   "metadata": {
    "id": "65f88182"
   },
   "source": [
    "#### Method #1: Dixon Q Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "934df987",
   "metadata": {
    "id": "934df987"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Enhanced Dixon Q Test\n",
    "\n",
    "@author: Emil Vassev\n",
    "\"\"\"\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "\"\"\"\n",
    " *\n",
    " * This class implements an enhanced version of DixonQ Test.\n",
    " * Provides a set of encoded critical values - up to 100.\n",
    " * The encoded critical values are used as a basis to generate critical values for other alphas (levels of confidence).\n",
    " * Both encoded and generated critical values are used to produce a result of maximum accuracy when identifying outliers.\n",
    " *\n",
    "\"\"\"\n",
    "class DixonQEnhanced:\n",
    "\n",
    "    criticalValues = {}\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     * DixonQEnhanced constructor\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.buildCriticalValues()\n",
    "        \n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\"\n",
    "    def getMethodName(self):\n",
    "        return \"DixonQ Enhanced Method\"\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     * Builds a dictionary of critical values grouped by alpha\n",
    "    \"\"\"\n",
    "    def buildCriticalValues(self):\n",
    "\n",
    "        \"\"\"\n",
    "         * the critical values are grouped by an alpha key\n",
    "         * alpha is the probability of incorrectly rejecting the suspected outlier\n",
    "        \"\"\"\n",
    "        #encoded critical values for alpha = 0.3 (0.7% level of confidence)\n",
    "        self.criticalValues[0.30] = [0,0,\n",
    "                                     0.6836,0.4704,0.3730,0.3173,0.2811,0.2550,0.2361,0.2208,\n",
    "                                     0.2086,0.1983,0.1898,0.1826,0.1764,0.1707,0.1656,0.1613,\n",
    "                                     0.1572,0.1535,0.1504,0.1474,0.1446,0.1420,0.1397,0.1376,\n",
    "                                     0.1355,0.1335,0.1318,0.1300,0.1283,0.1268,0.1255,0.1240,\n",
    "                                     0.1227,0.1215,0.1202,0.1192,0.1181,0.1169,0.1160,0.1153,\n",
    "                                     0.1141,0.1134,0.1124,0.1116,0.1108,0.1102,0.1093,0.1087,\n",
    "                                     0.1079,0.1071,0.1067,0.1060,0.1052,0.1047,0.1041,0.1036,\n",
    "                                     0.1030,0.1024,0.1019,0.1014,0.1009,0.1004,0.1000,0.0997,\n",
    "                                     0.0991,0.0987,0.0982,0.0979,0.0974,0.0970,0.0967,0.0961,\n",
    "                                     0.0960,0.0955,0.0952,0.0948,0.0943,0.0939,0.0937,0.0935,\n",
    "                                     0.0930,0.0928,0.0925,0.0921,0.0918,0.0915,0.0913,0.0910,\n",
    "                                     0.0906,0.0903,0.0902,0.0899,0.0896,0.0894,0.0892,0.0890,\n",
    "                                     0.0887,0.0885]\n",
    "\n",
    "        #encoded critical values for alpha = 0.2 (0.8% level of confidence)\n",
    "        self.criticalValues[0.20] = [0,0,\n",
    "                                     0.7808,0.5603,0.4508,0.3868,0.3444,0.3138,0.2915,0.2735,\n",
    "                                     0.2586,0.2467,0.2366,0.2280,0.2202,0.2137,0.2077,0.2023,\n",
    "                                     0.1973,0.1929,0.1890,0.1854,0.1820,0.1790,0.1761,0.1735,\n",
    "                                     0.1710,0.1687,0.1664,0.1645,0.1624,0.1604,0.1590,0.1571,\n",
    "                                     0.1555,0.1540,0.1525,0.1512,0.1499,0.1484,0.1472,0.1462,\n",
    "                                     0.1449,0.1441,0.1430,0.1418,0.1408,0.1400,0.1390,0.1381,\n",
    "                                     0.1374,0.1365,0.1357,0.1349,0.1340,0.1334,0.1326,0.1320,\n",
    "                                     0.1312,0.1304,0.1299,0.1294,0.1286,0.1281,0.1275,0.1272,\n",
    "                                     0.1264,0.1260,0.1254,0.1249,0.1243,0.1238,0.1234,0.1228,\n",
    "                                     0.1225,0.1221,0.1217,0.1212,0.1205,0.1201,0.1198,0.1195,\n",
    "                                     0.1189,0.1187,0.1182,0.1178,0.1174,0.1171,0.1167,0.1165,\n",
    "                                     0.1160,0.1156,0.1154,0.1151,0.1147,0.1144,0.1141,0.1138,\n",
    "                                     0.1134,0.1131]\n",
    "\n",
    "        #encoded critical values for alpha = 0.1 (0.9% level of confidence)\n",
    "        self.criticalValues[0.10] = [0,0,\n",
    "                                     0.8850,0.6789,0.5578,0.4840,0.4340,0.3979,0.3704,0.3492,\n",
    "                                     0.3312,0.3170,0.3045,0.2938,0.2848,0.2765,0.2691,0.2626,\n",
    "                                     0.2564,0.2511,0.2460,0.2415,0.2377,0.2337,0.2303,0.2269,\n",
    "                                     0.2237,0.2208,0.2182,0.2155,0.2132,0.2110,0.2088,0.2066,\n",
    "                                     0.2045,0.2026,0.2008,0.1993,0.1974,0.1958,0.1944,0.1930,\n",
    "                                     0.1915,0.1902,0.1890,0.1875,0.1865,0.1850,0.1839,0.1829,\n",
    "                                     0.1819,0.1808,0.1797,0.1788,0.1777,0.1768,0.1759,0.1752,\n",
    "                                     0.1741,0.1733,0.1726,0.1717,0.1707,0.1703,0.1694,0.1689,\n",
    "                                     0.1679,0.1674,0.1667,0.1660,0.1652,0.1648,0.1641,0.1635,\n",
    "                                     0.1631,0.1626,0.1620,0.1613,0.1605,0.1601,0.1596,0.1594,\n",
    "                                     0.1586,0.1583,0.1576,0.1573,0.1567,0.1563,0.1557,0.1554,\n",
    "                                     0.1547,0.1544,0.1540,0.1537,0.1532,0.1528,0.1524,0.1521,\n",
    "                                     0.1516,0.1512]\n",
    "\n",
    "        #encoded critical values for alpha = 0.05 (0.95% level of confidence)\n",
    "        self.criticalValues[0.05] = [0,0,\n",
    "                                     0.9411,0.7651,0.6423,0.5624,0.5077,0.4673,0.4363,0.4122,\n",
    "                                     0.3922,0.3755,0.3615,0.3496,0.3389,0.3293,0.3208,0.3135,\n",
    "                                     0.3068,0.3005,0.2947,0.2895,0.2851,0.2804,0.2763,0.2725,\n",
    "                                     0.2686,0.2655,0.2622,0.2594,0.2567,0.2541,0.2513,0.2488,\n",
    "                                     0.2467,0.2445,0.2423,0.2408,0.2383,0.2366,0.2350,0.2334,\n",
    "                                     0.2319,0.2302,0.2288,0.2273,0.2257,0.2241,0.2228,0.2216,\n",
    "                                     0.2206,0.2191,0.2182,0.2169,0.2160,0.2145,0.2135,0.2126,\n",
    "                                     0.2116,0.2106,0.2095,0.2085,0.2075,0.2070,0.2057,0.2053,\n",
    "                                     0.2045,0.2037,0.2030,0.2020,0.2013,0.2005,0.1996,0.1990,\n",
    "                                     0.1984,0.1980,0.1973,0.1964,0.1955,0.1950,0.1943,0.1940,\n",
    "                                     0.1934,0.1927,0.1922,0.1918,0.1909,0.1906,0.1899,0.1896,\n",
    "                                     0.1887,0.1885,0.1881,0.1876,0.1869,0.1865,0.1860,0.1856,\n",
    "                                     0.1851,0.1846]\n",
    "\n",
    "        #encoded critical values for alpha = 0.02 (0.98% level of confidence)\n",
    "        self.criticalValues[0.02] = [0,0,\n",
    "                                     0.9763,0.8457,0.7291,0.6458,0.5864,0.5432,0.5091,0.4813,\n",
    "                                     0.4591,0.4405,0.4250,0.4118,0.3991,0.3883,0.3792,0.3711,\n",
    "                                     0.3630,0.3562,0.3495,0.3439,0.3384,0.3328,0.3287,0.3242,\n",
    "                                     0.3202,0.3163,0.3127,0.3093,0.3060,0.3036,0.2999,0.2973,\n",
    "                                     0.2948,0.2921,0.2898,0.2879,0.2853,0.2836,0.2815,0.2794,\n",
    "                                     0.2778,0.2758,0.2744,0.2726,0.2711,0.2690,0.2676,0.2662,\n",
    "                                     0.2651,0.2632,0.2620,0.2606,0.2595,0.2582,0.2570,0.2555,\n",
    "                                     0.2545,0.2531,0.2522,0.2510,0.2500,0.2493,0.2480,0.2472,\n",
    "                                     0.2466,0.2457,0.2445,0.2436,0.2429,0.2420,0.2409,0.2402,\n",
    "                                     0.2398,0.2387,0.2382,0.2372,0.2365,0.2360,0.2349,0.2345,\n",
    "                                     0.2337,0.2330,0.2322,0.2319,0.2309,0.2304,0.2298,0.2294,\n",
    "                                     0.2285,0.2279,0.2272,0.2272,0.2259,0.2257,0.2251,0.2247,\n",
    "                                     0.2240,0.2234]\n",
    "\n",
    "        #encoded critical values for alpha = 0.01 (0.99% level of confidence)\n",
    "        self.criticalValues[0.01] = [0,0,\n",
    "                                     0.9881,0.8886,0.7819,0.6987,0.6371,0.5914,0.5554,0.5260,\n",
    "                                     0.5028,0.4831,0.4664,0.4517,0.4385,0.4268,0.4166,0.4081,\n",
    "                                     0.4002,0.3922,0.3854,0.3789,0.3740,0.3674,0.3625,0.3583,\n",
    "                                     0.3543,0.3499,0.3460,0.3425,0.3390,0.3357,0.3323,0.3294,\n",
    "                                     0.3266,0.3238,0.3213,0.3187,0.3163,0.3141,0.3124,0.3102,\n",
    "                                     0.3081,0.3061,0.3050,0.3028,0.3009,0.2991,0.2972,0.2960,\n",
    "                                     0.2941,0.2927,0.2920,0.2899,0.2880,0.2873,0.2859,0.2845,\n",
    "                                     0.2828,0.2816,0.2812,0.2792,0.2784,0.2775,0.2766,0.2754,\n",
    "                                     0.2742,0.2735,0.2724,0.2714,0.2709,0.2696,0.2682,0.2677,\n",
    "                                     0.2667,0.2662,0.2656,0.2646,0.2637,0.2633,0.2621,0.2614,\n",
    "                                     0.2608,0.2599,0.2588,0.2584,0.2573,0.2568,0.2566,0.2558,\n",
    "                                     0.2548,0.2543,0.2539,0.2535,0.2524,0.2521,0.2512,0.2513,\n",
    "                                     0.2499,0.2498]\n",
    "\n",
    "        #encoded critical values for alpha = 0.005 (0.995% level of confidence)\n",
    "        self.criticalValues[0.005] = [0,0,\n",
    "                                     0.9940,0.9201,0.8234,0.7437,0.6809,0.6336,0.5952,0.5668,\n",
    "                                     0.5416,0.5208,0.5034,0.4869,0.4739,0.4614,0.4504,0.4423,\n",
    "                                     0.4333,0.4247,0.4173,0.4109,0.4051,0.3986,0.3935,0.3889,\n",
    "                                     0.3843,0.3801,0.3762,0.3718,0.3685,0.3646,0.3610,0.3583,\n",
    "                                     0.3548,0.3522,0.3498,0.3465,0.3443,0.3415,0.3400,0.3377,\n",
    "                                     0.3353,0.3332,0.3325,0.3298,0.3279,0.3256,0.3235,0.3225,\n",
    "                                     0.3204,0.3191,0.3177,0.3163,0.3140,0.3136,0.3118,0.3098,\n",
    "                                     0.3089,0.3075,0.3071,0.3061,0.3041,0.3031,0.3025,0.3006,\n",
    "                                     0.2996,0.2990,0.2983,0.2968,0.2959,0.2946,0.2934,0.2932,\n",
    "                                     0.2922,0.2912,0.2905,0.2897,0.2885,0.2876,0.2870,0.2859,\n",
    "                                     0.2852,0.2844,0.2836,0.2832,0.2818,0.2811,0.2808,0.2798,\n",
    "                                     0.2790,0.2788,0.2784,0.2775,0.2766,0.2764,0.2755,0.2751,\n",
    "                                     0.2738,0.2737]\n",
    "\n",
    "        \"\"\"\n",
    "         * Generates all critical values by using the encoded values as a basis.\n",
    "         * Values are genereated between any two existing pairs of alphas.\n",
    "        \"\"\"\n",
    "        #generate range alpha 0.2 - 0.1\n",
    "        self.generateCriticalValuesForAlphaPair(0.2,0.1)\n",
    "\n",
    "        #generate range alpha 0.3 - 0.2\n",
    "        self.generateCriticalValuesForAlphaPair(0.3,0.2)\n",
    "\n",
    "        #generate range alpha 0.10 - 0.05\n",
    "        self.generateCriticalValuesForAlphaPair(0.10,0.05)\n",
    "\n",
    "        #generate range alpha 0.05 - 0.02\n",
    "        self.generateCriticalValuesForAlphaPair(0.05,0.02)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     * Generates the missing series of critical values between two alphas with a step = 0.01\n",
    "     * constraint: alpha1 > alpha2\n",
    "    \"\"\"\n",
    "    def generateCriticalValuesForAlphaPair(self, alpha1, alpha2):\n",
    "\n",
    "        if alpha1 < alpha2:\n",
    "            raise Exception('The value of alpha1 is less than alpha2.')\n",
    "\n",
    "        nInsideAlphas = int(round((alpha1 - alpha2)/(0.01)) - 1)\n",
    "\n",
    "        insideAlphas = []\n",
    "\n",
    "        step = 0.01\n",
    "        for i in range(1,nInsideAlphas+1):\n",
    "            newAlpha = round(alpha2 + i*step,2)\n",
    "            insideAlphas.append(newAlpha)\n",
    "\n",
    "        for index in range(2,100):\n",
    "\n",
    "            rangeLeft = self.criticalValues[alpha1][index]\n",
    "            rangeRight = self.criticalValues[alpha2][index]\n",
    "\n",
    "            distance = round(((rangeRight - rangeLeft)/(nInsideAlphas+1)),4)\n",
    "\n",
    "            currentValue = self.criticalValues[alpha1][index]\n",
    "\n",
    "            for insideAlpha in insideAlphas:\n",
    "\n",
    "                if insideAlpha not in self.criticalValues.keys():\n",
    "                    self.criticalValues[insideAlpha] = []\n",
    "                    self.criticalValues[insideAlpha].append(0)\n",
    "                    self.criticalValues[insideAlpha].append(0)\n",
    "\n",
    "                currentValue += distance\n",
    "\n",
    "                currentValue = round(currentValue,4)\n",
    "\n",
    "                self.criticalValues[insideAlpha].append(currentValue)\n",
    "\n",
    "    \"\"\"\n",
    "     * Finds the next element in a series of elements\n",
    "    \"\"\"\n",
    "    def findNextInSeries(self, number, series):\n",
    "\n",
    "        result = -1\n",
    "\n",
    "        try:\n",
    "            index = series.index(number)\n",
    "        except ValueError as e:\n",
    "            raise Exception('The number has not been found in the series.')\n",
    "\n",
    "        if index == (len(series) - 1):\n",
    "            result = index - 1\n",
    "        else:\n",
    "            result = index + 1\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     * Finds the previous element in a series of elements\n",
    "    \"\"\"\n",
    "    def findPreviousInSeries(self, number, series):\n",
    "\n",
    "        result = -1\n",
    "\n",
    "        try:\n",
    "            index = series.index(number)\n",
    "        except ValueError as e:\n",
    "            raise Exception('The number has not been found in the series.')\n",
    "\n",
    "        if index == 0:\n",
    "            result = index + 1\n",
    "        else:\n",
    "            result = index - 1\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     * Identifies if a number is outlier within a series and for particular alpha\n",
    "    \"\"\"\n",
    "    def isOutlier(self, number, series, alpha):\n",
    "\n",
    "        qCritical = 0.0\n",
    "\n",
    "        qExpDivisor = series[len(series)-1] - series[0]\n",
    "\n",
    "        if qExpDivisor == 0:\n",
    "            return False\n",
    "\n",
    "        if len(series) > 100:\n",
    "            return False\n",
    "\n",
    "        nextNumberGap = abs(number - series[self.findNextInSeries(number,series)])\n",
    "        prevNumberGap = abs(number - series[self.findPreviousInSeries(number,series)])\n",
    "        if prevNumberGap < nextNumberGap:\n",
    "            closestNumberGap = prevNumberGap\n",
    "        else:\n",
    "            closestNumberGap = nextNumberGap\n",
    "\n",
    "        qExp = closestNumberGap/qExpDivisor\n",
    "\n",
    "        if alpha in self.criticalValues.keys():\n",
    "            qCritical = self.criticalValues[alpha][len(series)-1]\n",
    "\n",
    "        if qExp > qCritical:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     * Identifies all the outliers within a series\n",
    "     * Uses the isOutlier method\n",
    "    \"\"\"\n",
    "    def findOutliers(self, series):\n",
    "\n",
    "        outliers = {}\n",
    "\n",
    "        for alpha in self.criticalValues.keys():\n",
    "            for number in series:\n",
    "                if self.isOutlier(number,series,alpha):\n",
    "                    if number in outliers:\n",
    "                        if outliers[number] < (1-alpha):\n",
    "                            outliers[number] = (1-alpha)\n",
    "                    else:\n",
    "                        outliers[number] = (1-alpha)\n",
    "\n",
    "        return outliers\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     * Checks if the data set is normally distributed;\n",
    "     * running DixonQ Test on different distributions will lead to erroneous results\n",
    "     *\n",
    "     * Runs a Shapiro-Wilk test to check if the series is Gaussian\n",
    "    \"\"\"\n",
    "    def checkForNormalDisribution(self, series):\n",
    "\n",
    "        print(\"Shapiro-Wilk: Running Shapiro-Wilk test ....\")\n",
    "\n",
    "        stat, p = shapiro(series)\n",
    "\n",
    "        alpha = 0.05\n",
    "\n",
    "        if p > alpha:\n",
    "            print(\"Shapiro-Wilk: Series looks Gaussian\")\n",
    "            #print(\"\")\n",
    "            return True\n",
    "\n",
    "        else:\n",
    "            print(\"Shapiro-Wilk: Series does not look Gaussian\")\n",
    "            #print(\"\")\n",
    "            return False\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     * Executes DixonQ Test on the provided series of numbers;\n",
    "     * DixonQ Test is executed for all available alpha keys (levels of confidence)\n",
    "    \"\"\"\n",
    "    def execute(self, series):\n",
    "\n",
    "        outliers = {}\n",
    "\n",
    "        series.sort(reverse=False)\n",
    "\n",
    "        if not self.checkForNormalDisribution(series):\n",
    "            print(\"DixonQ Test: Warning: Test should not be run on a series that is not normally distributed.\")\n",
    "\n",
    "        outliers = self.findOutliers(series)\n",
    "\n",
    "        return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554405a2",
   "metadata": {
    "id": "554405a2"
   },
   "source": [
    "#### Method #2: Mean & Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8086aac4",
   "metadata": {
    "id": "8086aac4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\"\"\"\n",
    " * This class implements the Standard Deviation Method for detecting outliers\n",
    "\"\"\"\n",
    "class StandardDeviationMethod:\n",
    "\n",
    "\n",
    "    methodName = \"StandardDeviationMethod\"\n",
    "\n",
    "    upperLimit = 0.0\n",
    "    lowerLimit = 0.0\n",
    "    seriesStd = 0.0\n",
    "    seriesMean = 0.0\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "\n",
    "        pass\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\"\n",
    "    def getMethodName(self):\n",
    "        return \"StandardDeviationMethod Method\"\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\"\n",
    "    def getMethodName(self):\n",
    "        return \"Standard Deviation Method\"\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     * Function to detect outliers on one-dimentional datasets\n",
    "    \"\"\"\n",
    "    def execute(self, series):\n",
    "\n",
    "        outliers = []\n",
    "\n",
    "        # set upper and lower limits to 3 times the standard deviation\n",
    "        seriesStd = np.std(series)\n",
    "        seriesMean = np.mean(series)\n",
    "        #anomalyCutOff = seriesStd * 3\n",
    "        #anomalyCutOff = seriesStd * 2\n",
    "        #anomalyCutOff = seriesStd * 1.5\n",
    "        #anomalyCutOff = seriesStd * 1.75\n",
    "        anomalyCutOff = seriesStd * 2.5\n",
    "\n",
    "        lowerLimit  = seriesMean - anomalyCutOff\n",
    "        upperLimit = seriesMean + anomalyCutOff\n",
    "\n",
    "        #print(lowerLimit)\n",
    "\n",
    "        self.upperLimit = upperLimit\n",
    "        self.lowerLimit = lowerLimit\n",
    "        self.seriesStd = seriesStd\n",
    "        self.seriesMean = seriesMean\n",
    "\n",
    "        # generate outliers\n",
    "        for outlier in series:\n",
    "            if outlier > upperLimit or outlier < lowerLimit:\n",
    "                outliers.append(outlier)\n",
    "\n",
    "        return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f15ac6d",
   "metadata": {
    "id": "7f15ac6d"
   },
   "source": [
    "#### Method #3: Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56fd2304",
   "metadata": {
    "id": "56fd2304"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    " * This class implements the Isolation Forest Method for detecting outliers\n",
    "\"\"\"\n",
    "class IsolationForestMethod:\n",
    "\n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\"\n",
    "    def getMethodName(self):\n",
    "        return \"Isolation Forest Method\"\n",
    "    \n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\"\n",
    "    def checkAllElementsEqual(self, series):\n",
    "        return len(set(series)) <= 1\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     * Function to detect outliers on one-dimentional datasets\n",
    "    \"\"\"\n",
    "    def execute(self, series):\n",
    "        outliers = []\n",
    "\n",
    "        if not self.checkAllElementsEqual(series):\n",
    "            df = pd.DataFrame({'temp':series})\n",
    "            clf = IsolationForest().fit(df['temp'].values.reshape(-1, 1))\n",
    "            outliersInds = clf.predict(df['temp'].values.reshape(-1, 1))\n",
    "\n",
    "            for indx in range(0, len(outliersInds)):\n",
    "                if outliersInds[indx] == -1:\n",
    "                    outliers.append(series[indx])\n",
    "\n",
    "        return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6971e8",
   "metadata": {
    "id": "6c6971e8"
   },
   "source": [
    "#### Method #4: Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2be4b396",
   "metadata": {
    "id": "2be4b396"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib.cbook import boxplot_stats\n",
    "\n",
    "\"\"\"\n",
    " * This class implements the Boxplots Method for detecting outliers\n",
    "\"\"\"\n",
    "class BoxPlotsMethod:\n",
    "\n",
    "    methodName = \"BoxPlotsMethod\"\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\"\n",
    "    def getMethodName(self):\n",
    "        return \"Boxplots Method\"\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     * Function to detect outliers on one-dimentional datasets\n",
    "    \"\"\"\n",
    "    def execute(self, series):\n",
    "        outliers = []\n",
    "\n",
    "        ax = sns.boxplot(data=series, whis=2.5)\n",
    "\n",
    "        outliers = [y for stat in boxplot_stats(series) for y in stat['fliers']]\n",
    "\n",
    "        return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c282d1",
   "metadata": {
    "id": "e0c282d1"
   },
   "source": [
    "#### Method #5:  DBSCAN Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30d163d2",
   "metadata": {
    "id": "30d163d2"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    " * This class implements the DBScan Clustering Method for detecting outliers\n",
    "\"\"\"\n",
    "class DBScanClusteringMethod:\n",
    "\n",
    "\n",
    "    methodName = \"DBScanClusteringMethod\"\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "\n",
    "        pass\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\"\n",
    "    def checkAllElementsEqual(self, series):\n",
    "        return len(set(series)) <= 1\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\"\n",
    "    def getMethodName(self):\n",
    "        return \"DBScan Clustering Method\"\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     * Function to detect outliers on one-dimentional datasets\n",
    "    \"\"\"\n",
    "    def execute(self, series):\n",
    "        outliers = []\n",
    "\n",
    "        if not self.checkAllElementsEqual(series):\n",
    "\n",
    "            df = pd.DataFrame({'temp':series})\n",
    "            outliersDetection = DBSCAN(min_samples = 2, eps = 0.5)\n",
    "            outliersInds = outliersDetection.fit_predict(df['temp'].values.reshape(-1, 1))\n",
    "\n",
    "            for indx in range(0, len(outliersInds)):\n",
    "\n",
    "                if outliersInds[indx] == -1:\n",
    "                    outliers.append(series[indx])\n",
    "\n",
    "        return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7679f1b",
   "metadata": {
    "id": "c7679f1b"
   },
   "source": [
    "#### CryptoCompare Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bb219d6",
   "metadata": {
    "id": "4bb219d6"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Emil Vassev\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "CryptoCompare.com Reader class - uses CryptoCompare.com API to retrieve history data\n",
    "\"\"\"\n",
    "class CryptoCompareReader:\n",
    "\n",
    "    apiKey = \"fe6382d7770ad0c939c5c12d51e76ab772afbc361f2900405fe8bc930e31ed97\"\n",
    "    urlCurrent = \"https://min-api.cryptocompare.com/data/pricemulti?fsyms=$1&tsyms=USD&api_key=\" + apiKey\n",
    "    urlHistory = \"https://min-api.cryptocompare.com/data/v2/histoday?fsym=$1&tsym=USD&limit=$2\"\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def extractCoinRates(self, apiResult):\n",
    "        usdToCoinRates = []\n",
    "\n",
    "        data = apiResult.get(\"Data\").get(\"Data\")\n",
    "\n",
    "        for cryptoCurrency in data:\n",
    "            coinResult = cryptoCurrency[\"close\"]\n",
    "            usdToCoinRates.append(coinResult)\n",
    "\n",
    "        return usdToCoinRates\n",
    "\n",
    "\n",
    "    def readHistoryRates (self, cryptoCurrency, size):\n",
    "\n",
    "        urlRestAPI = self.urlHistory.replace(\"$1\", cryptoCurrency)\n",
    "\n",
    "        urlRestAPI = urlRestAPI.replace(\"$2\", str(size))  # Convert size to string here\n",
    "\n",
    "        response = requests.get(urlRestAPI)\n",
    "\n",
    "        return self.extractCoinRates(response.json())\n",
    "\n",
    "\n",
    "    def readCurrentRate (self, cryptoCurrency):\n",
    "\n",
    "        urlRestAPI = self.urlCurrent.replace(\"$1\", cryptoCurrency)\n",
    "\n",
    "        response = requests.get(urlRestAPI).json()\n",
    "\n",
    "        coinRate = response[cryptoCurrency].get('USD')\n",
    "\n",
    "        return coinRate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd582f1",
   "metadata": {
    "id": "2fd582f1"
   },
   "source": [
    "#### AWS S3 Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b7072eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AWS_ACCESS_KEY_ID = \"AKIA57LSAMJH4GSEFP3Z\"\n",
    "#AWS_SECRET_ACCESS_KEY = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e072ac80",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "id": "e072ac80",
    "outputId": "ae2b04ea-77e6-4e26-ac1b-2a9b117f93aa"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Eoghan Mulcahy\n",
    "\"\"\"\n",
    "\n",
    "from lib2to3.pgen2.pgen import DFAState\n",
    "import numpy as np\n",
    "import boto3\n",
    "import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "\"\"\"\n",
    " * This class provides utility functions to interact with S3\n",
    "\"\"\"\n",
    "class S3Utils:\n",
    "\n",
    "\n",
    "    methodName = \"S3Utils\"\n",
    "\n",
    "    \"\"\"\n",
    "     Utility class for bucket ops\n",
    "    \"\"\"\n",
    "    def __init__(self, bucket_name : str):\n",
    "        self.bucket_name = bucket_name\n",
    "\n",
    "    def _delete_file_(self, file_name: str):\n",
    "        s3.delete_object(\n",
    "            Key=file_name,\n",
    "            Bucket=self.bucket_name,\n",
    "        )\n",
    "\n",
    "    def _upload_file_(self, file_name: str):\n",
    "        file_size = os.stat(file_name).st_size\n",
    "        with tqdm.tqdm(total=file_size, unit=\"B\", unit_scale=True, desc=file_name) as pbar:\n",
    "            s3.upload_file(\n",
    "                Filename=file_name,\n",
    "                Bucket=self.bucket_name,\n",
    "                Key=file_name,\n",
    "                Callback=lambda bytes_transferred: pbar.update(bytes_transferred),\n",
    "            )\n",
    "\n",
    "    def _download_file_(self, file_name: str):\n",
    "        # Ensure the directory exists\n",
    "        data_dir = './data/'\n",
    "        if not os.path.exists(data_dir):\n",
    "            os.makedirs(data_dir)\n",
    "        \n",
    "        file_path = data_dir + file_name\n",
    "        object_size = s3.head_object(Bucket=self.bucket_name, Key=file_name)['ContentLength']\n",
    "        with tqdm.tqdm(total=object_size, unit=\"B\", unit_scale=True, desc=file_name) as pbar:\n",
    "            s3.download_file(\n",
    "                Bucket=self.bucket_name,\n",
    "                Key=file_name,\n",
    "                Filename=file_path,\n",
    "                Callback=lambda bytes_transferred: pbar.update(bytes_transferred)\n",
    "            )\n",
    "            \n",
    "    \"\"\"\n",
    "     Uploads a file to the bucket\n",
    "    \"\"\"\n",
    "    def addFileToBucket(self, file_name: str):\n",
    "        self._upload_file_(file_name)\n",
    "\n",
    "    \"\"\"\n",
    "     Appends one row to the csv file in bucket\n",
    "    \"\"\"\n",
    "    def writeRowToCsvFileInBucket(self, file_name: str, values: list):\n",
    "        # If not exists in data folder download\n",
    "        if not os.path.exists('./data/' + file_name):\n",
    "            self._download_file_(file_name)\n",
    "        # convert to a dataframe and return to caller\n",
    "        df = pd.read_csv('./data/' + file_name)\n",
    "        df_new_line = pd.DataFrame([values], columns=df.columns)\n",
    "        df_new_line.to_csv(file_name, mode='a', index=False, header=False)\n",
    "        self._delete_file_(file_name)\n",
    "        self._upload_file_(file_name)\n",
    "\n",
    "    \"\"\"\n",
    "     Gets a csv file from bucket and returns a dataframe\n",
    "    \"\"\"\n",
    "    def readCsvFileFromBucket(self, file_name: str) -> pd.DataFrame:\n",
    "        if os.path.exists('./data/' + file_name):\n",
    "            os.remove('./data/' + file_name)\n",
    "        self._download_file_(file_name)\n",
    "        return pd.read_csv('./data/' + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46adaea",
   "metadata": {
    "id": "e46adaea"
   },
   "source": [
    "### Your Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b74df5c",
   "metadata": {
    "id": "6b74df5c"
   },
   "source": [
    "Implement your solution by following the structure of the <i>CS6512Assignment2</i> class.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "238fa3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "instrument_price.csv: 100%|██████████| 8.16M/8.16M [00:00<00:00, 66.1MB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instrument_ticker</th>\n",
       "      <th>currency_code</th>\n",
       "      <th>bid</th>\n",
       "      <th>offer</th>\n",
       "      <th>pricing_source_code</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LINK</td>\n",
       "      <td>USD</td>\n",
       "      <td>18.08329</td>\n",
       "      <td>18.08329</td>\n",
       "      <td>KRAKEN</td>\n",
       "      <td>2/10/2022 6:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTC</td>\n",
       "      <td>USD</td>\n",
       "      <td>43821.37500</td>\n",
       "      <td>43821.37500</td>\n",
       "      <td>COINBASE</td>\n",
       "      <td>2/10/2022 6:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LTC</td>\n",
       "      <td>USD</td>\n",
       "      <td>138.06000</td>\n",
       "      <td>138.06000</td>\n",
       "      <td>KRAKEN</td>\n",
       "      <td>2/10/2022 6:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAI</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.01890</td>\n",
       "      <td>1.01890</td>\n",
       "      <td>BINANCE</td>\n",
       "      <td>2/10/2022 6:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XRP</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.87150</td>\n",
       "      <td>0.87150</td>\n",
       "      <td>BINANCE</td>\n",
       "      <td>2/10/2022 6:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SOL</td>\n",
       "      <td>USD</td>\n",
       "      <td>111.41500</td>\n",
       "      <td>111.41500</td>\n",
       "      <td>COINBASE</td>\n",
       "      <td>2/10/2022 6:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BTC</td>\n",
       "      <td>USD</td>\n",
       "      <td>43916.90000</td>\n",
       "      <td>43916.90000</td>\n",
       "      <td>KRAKEN</td>\n",
       "      <td>2/10/2022 6:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XRP</td>\n",
       "      <td>USD</td>\n",
       "      <td>0.87188</td>\n",
       "      <td>0.87188</td>\n",
       "      <td>KRAKEN</td>\n",
       "      <td>2/10/2022 6:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BTC</td>\n",
       "      <td>USD</td>\n",
       "      <td>43819.80000</td>\n",
       "      <td>43819.80000</td>\n",
       "      <td>KRAKEN</td>\n",
       "      <td>2/10/2022 6:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>USD</td>\n",
       "      <td>CAD</td>\n",
       "      <td>1.26800</td>\n",
       "      <td>1.26800</td>\n",
       "      <td>BANKOFCANADA</td>\n",
       "      <td>2/10/2022 5:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  instrument_ticker currency_code          bid        offer  \\\n",
       "0              LINK           USD     18.08329     18.08329   \n",
       "1               BTC           USD  43821.37500  43821.37500   \n",
       "2               LTC           USD    138.06000    138.06000   \n",
       "3               DAI           USD      1.01890      1.01890   \n",
       "4               XRP           USD      0.87150      0.87150   \n",
       "5               SOL           USD    111.41500    111.41500   \n",
       "6               BTC           USD  43916.90000  43916.90000   \n",
       "7               XRP           USD      0.87188      0.87188   \n",
       "8               BTC           USD  43819.80000  43819.80000   \n",
       "9               USD           CAD      1.26800      1.26800   \n",
       "\n",
       "  pricing_source_code            time  \n",
       "0              KRAKEN  2/10/2022 6:31  \n",
       "1            COINBASE  2/10/2022 6:31  \n",
       "2              KRAKEN  2/10/2022 6:31  \n",
       "3             BINANCE  2/10/2022 6:31  \n",
       "4             BINANCE  2/10/2022 6:01  \n",
       "5            COINBASE  2/10/2022 6:31  \n",
       "6              KRAKEN  2/10/2022 6:01  \n",
       "7              KRAKEN  2/10/2022 6:01  \n",
       "8              KRAKEN  2/10/2022 6:31  \n",
       "9        BANKOFCANADA  2/10/2022 5:31  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name = 'ptrayers-ul-cs6512'\n",
    "AWS_S3_BUCKET = bucket_name\n",
    "\n",
    "s3_client = S3Utils(AWS_S3_BUCKET)\n",
    "\n",
    "df = s3_client.readCsvFileFromBucket('instrument_price.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1a3df4ad",
   "metadata": {
    "id": "1a3df4ad"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Paul Trayers, 8907021\n",
    "\"\"\"\n",
    "\n",
    "#add your imports here\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "class CS6512Assignment2:\n",
    "\n",
    "    sereisCSV = []\n",
    "    seriesCrptCmpr = []\n",
    "\n",
    "\n",
    "    #describes a series and saves the result to a file\n",
    "    def describeSereis(self, series, fileName):\n",
    "\n",
    "        #add your code here\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "    #extracts a cryptocurrency series from a provided dataframe\n",
    "    def extractSeriesFromDF(self, df, cryptoCurrency):\n",
    "\n",
    "        #series = []\n",
    "\n",
    "        #add your code here\n",
    "        \n",
    "        # Check if the necessary columns exist in the DataFrame\n",
    "        if 'instrument_ticker' not in df.columns:\n",
    "            raise ValueError(\"DataFrame does not contain the column 'instrument_ticker'\")\n",
    "        if 'offer' not in df.columns:\n",
    "            raise ValueError(\"DataFrame does not contain the column 'offer'\")\n",
    "    \n",
    "        # Filter the DataFrame based on the cryptocurrency ticker, (df_instrument is type DataFrame)\n",
    "        df_instrument = df.loc[df['instrument_ticker'] == cryptoCurrency]\n",
    "    \n",
    "        # Check if there are any matches, otherwise return an empty series or handle as needed\n",
    "        if df_instrument.empty:\n",
    "            raise ValueError(\"No entries found for the specified cryptocurrency\")\n",
    "    \n",
    "        # return the 'offer' column (df_instrument is type DataFrame, series_instrument is a Series)\n",
    "        series_instrument = df_instrument['offer']\n",
    "        return series_instrument\n",
    "\n",
    "\n",
    "    #gets a cryptocurrency series from CryptoCompare.com\n",
    "    def extractSeriesFromCryptoCompare(self, cryptoCurrency):\n",
    "\n",
    "        series = []\n",
    "\n",
    "        #add your code here\n",
    "        #use the CryptoCompareReader class to get a history of 600 rates\n",
    "        \n",
    "        cryptoCompare = CryptoCompareReader()\n",
    "        #current_rate = cryptoCompare.readCurrentRate(cryptoCurrency)\n",
    "        #print(f\"Current Rate: {current_rate}\")\n",
    "        \n",
    "        rates_history = cryptoCompare.readHistoryRates(cryptoCurrency, 600)\n",
    "        \n",
    "        # Convert from Python list to a pandas Series (for executePhase method)\n",
    "        series = pd.Series(rates_history)\n",
    "\n",
    "        return series\n",
    "\n",
    "\n",
    "    #extracts 100 elements from a series at random\n",
    "    def extract100ElementsAtRandom(self, \n",
    "                                   series  # type Pandas Series\n",
    "                                  ):\n",
    "\n",
    "        #series100 = []\n",
    "        #add your code here\n",
    "        \n",
    "        # Check if the series has at least 100 elements\n",
    "        if len(series) < 100:\n",
    "            raise ValueError(\"The series does not contain enough elements to extract 100 items.\")\n",
    "\n",
    "        # Randomly sample 100 elements from the series, without replacement\n",
    "        series100 = series.sample(n=100)\n",
    "\n",
    "        return series100\n",
    "\n",
    "\n",
    "    #executes the Dixon Q method\n",
    "    def executeDixonQ(self, series):\n",
    "\n",
    "        outliers = []\n",
    "        \n",
    "        #add your code here\n",
    "        outlier_detect_method = DixonQEnhanced()\n",
    "        method_name = outlier_detect_method.getMethodName()\n",
    "        print(f\"Executing {method_name}...\")\n",
    "        outliers = outlier_detect_method.execute(series)\n",
    "\n",
    "        return outliers\n",
    "\n",
    "\n",
    "    #executes the Standard Deviation method\n",
    "    def executeStandardDeviation(self, series):\n",
    "\n",
    "        outliers = []\n",
    "        \n",
    "        #add your code here\n",
    "        outlier_detect_method = StandardDeviationMethod()\n",
    "        method_name = outlier_detect_method.getMethodName()\n",
    "        print(f\"Executing {method_name}...\")\n",
    "        outliers = outlier_detect_method.execute(series)\n",
    "\n",
    "        return outliers\n",
    "\n",
    "\n",
    "    #executes the Isolation Forest method\n",
    "    def executeIsolationForest(self, series):\n",
    "\n",
    "        outliers = []\n",
    "        \n",
    "        #add your code here\n",
    "        outlier_detect_method = IsolationForestMethod()\n",
    "        method_name = outlier_detect_method.getMethodName()\n",
    "        print(f\"Executing {method_name}...\")\n",
    "        outliers = outlier_detect_method.execute(series)\n",
    "\n",
    "        return outliers\n",
    "\n",
    "\n",
    "    #executes the Boxplots method\n",
    "    def executeBoxplots(self, series):\n",
    "\n",
    "        outliers = []\n",
    "        \n",
    "        #add your code here\n",
    "        outlier_detect_method = BoxPlotsMethod()\n",
    "        method_name = outlier_detect_method.getMethodName()\n",
    "        print(f\"Executing {method_name}...\")\n",
    "        outliers = outlier_detect_method.execute(series)\n",
    "\n",
    "        return outliers\n",
    "\n",
    "\n",
    "    #executes the DBSCAN Clustering method\n",
    "    def executeDBSCANClustering(self, series):\n",
    "\n",
    "        outliers = []\n",
    "        \n",
    "        #add your code here\n",
    "        outlier_detect_method = DBScanClusteringMethod()\n",
    "        method_name = outlier_detect_method.getMethodName()\n",
    "        print(f\"Executing {method_name}...\")\n",
    "        outliers = outlier_detect_method.execute(series)\n",
    "        \n",
    "        return outliers\n",
    "\n",
    "    #execute method\n",
    "    def executeMethod(self, method, series):\n",
    "\n",
    "        print(f\"Executing {method.getMethodName()}...\")\n",
    "        return outlier_detect_method.execute(series)\n",
    "    \n",
    "    \n",
    "    #records the joint-outliers results into your S3 storage\n",
    "    #JSON format:\n",
    "    # {\n",
    "    #  \"Series_100\": [83.825, 84.715, 86.94, 88.1, 90.0, 90.365, 91.21, 92.16, 92.74, 94.0,\n",
    "    #                 94.31, 95.0, 95.37, 95.49, 96.315, 97.67, 98.805, 102.94, 108.46, 109.73,\n",
    "    #                 110.03, 110.42, 111.34, 111.89, 113.0, 113.25, 113.39, 113.88, 114.73,\n",
    "    #                 114.87, 115.22, 117.37, 122.57, 133.37, 133.995, 135.58, 136.26, 136.52,\n",
    "    #                 136.67, 136.82, 137.22, 138.18, 138.33, 140.57, 142.19, 142.4, 143.65,\n",
    "    #                 146.98, 147.27, 147.27, 147.89, 148.225, 148.31, 148.34, 148.435, 148.9,\n",
    "    #                 152.285, 154.34, 159.11, 159.89, 167.88, 169.0, 169.69, 169.775, 170.74,\n",
    "    #                 170.82, 171.17, 171.22, 171.24, 171.86, 171.88, 172.13, 172.39, 172.4, 173.96,\n",
    "    #                 174.67, 175.035, 175.4, 175.66, 175.84, 176.52, 178.37, 179.2, 179.47,\n",
    "    #                 179.79, 179.95, 181.94, 182.01, 188.0, 188.26, 188.4, 189.25, 191.04,\n",
    "    #                 192.53, 197.05, 198.28, 198.34, 198.69, 200.4, 235.18],\n",
    "    #  \"Dixon_Q\": [235.18],\n",
    "    #  \"Standard_Deviation\": [235.18],\n",
    "    #  \"Isolation_Forest\": [83.825, 84.715, 86.94, 88.1, 90.0, 90.365, 91.21, 92.16, 92.74, 96.315, 97.67,\n",
    "    #                       98.805, 102.94, 108.46, 117.37, 122.57, 154.34, 159.11, 159.89, 167.88, 181.94,\n",
    "    #                       182.01, 188.0, 189.25, 191.04, 192.53, 197.05, 198.28, 198.34, 198.69, 200.4, 235.18],\n",
    "    #  \"Boxplots\": [40.0, 60.0, 63.0, 63.0, 64.0, 65.0, 169.114286, 169.429444, 172.353, 197.4606, 235.18],\n",
    "    #  \"DBSCAN_Clustering\": [40, 60, 64, 65, 72.5126, 75.671004, 79.782605, 91.300919, 92, 94.931864, 96,\n",
    "    #                        103.824548, 104.851577, 105.948, 109.593951, 113.338919, 114.672941, 116.48158,\n",
    "    #                        118.7118, 122.25, 122.873307, 124.339492, 125.154034, 136.782077, 143.9881,\n",
    "    #                        146.902942, 156.476319, 159.2281, 164.957759, 167.574109, 172.353, 197.4606, 235.18],\n",
    "    #  \"Joint_Outliers\": [235.18]\n",
    "    # }\n",
    "    def produceJsonOutliers(self,\n",
    "                            json_file_name,\n",
    "                            series_100,\n",
    "                            outliers_DQ,\n",
    "                            outliers_StD,\n",
    "                            outliers_IF,\n",
    "                            outliers_BXPLTS,\n",
    "                            outliers_DBSCAN_CL,\n",
    "                            joint_outliers,\n",
    "                            joint_outliers_DQ_StD,\n",
    "                            joint_outliers_DQ_IF,\n",
    "                            joint_outliers_DQ_BXPLTS,\n",
    "                            joint_outliers_DQ_DBSCAN_CL,\n",
    "                            joint_outliers_StD_IF,\n",
    "                            joint_outliers_StD_BXPLTS,\n",
    "                            joint_outliers_StD_DBSCAN_CL,\n",
    "                            joint_outliers_IF_BXPLTS,\n",
    "                            joint_outliers_IF_DBSCAN_CL,\n",
    "                            joint_outliers_BXPLTS_DBSCAN_CL):\n",
    "\n",
    "        #add your code here\n",
    "        \n",
    "        # Data to be written\n",
    "        output_data = {\n",
    "            \"Series_100\": list(series_100),\n",
    "            \"Dixon_Q\": list(outliers_DQ),\n",
    "            \"Standard_Deviation\": list(outliers_StD),\n",
    "            \"Isolation_Forest\": list(outliers_IF),\n",
    "            \"Boxplots\": list(outliers_BXPLTS),\n",
    "            \"DBSCAN_Clustering\": list(outliers_DBSCAN_CL),\n",
    "            \"Joint_Outliers\": list(joint_outliers),            \n",
    "            \"Joint_Outliers_DQ_StD\": list(joint_outliers_DQ_StD),\n",
    "            \"Joint_Outliers_DQ_IF\": list(joint_outliers_DQ_IF),\n",
    "            \"Joint_Outliers_DQ_BXPLTS\": list(joint_outliers_DQ_BXPLTS),\n",
    "            \"Joint_Outliers_DQ_DBSCAN_CL\": list(joint_outliers_DQ_DBSCAN_CL),\n",
    "            \"Joint_Outliers_StD_IF\": list(joint_outliers_StD_IF),\n",
    "            \"Joint_Outliers_StD_BXPLTS\": list(joint_outliers_StD_BXPLTS),\n",
    "            \"Joint_Outliers_StD_DBSCAN_CL\": list(joint_outliers_StD_DBSCAN_CL),\n",
    "            \"Joint_Outliers_IF_BXPLTS\": list(joint_outliers_IF_BXPLTS),\n",
    "            \"Joint_Outliers_IF_DBSCAN_CL\": list(joint_outliers_IF_DBSCAN_CL),\n",
    "            \"Joint_Outliers_BXPLTS_DBSCAN_CL\": list(joint_outliers_BXPLTS_DBSCAN_CL)\n",
    "        }\n",
    "        print(f\"JSON format:\\n{output_data}\")        \n",
    "        \n",
    "        # Write to JSON file\n",
    "        with open(json_file_name, 'w') as f:\n",
    "            json.dump(output_data, f, indent=4)\n",
    "        print(f\"\\nData written to {json_file_name}.\")\n",
    "\n",
    "        # Upload to S3 bucket\n",
    "        s3_client.addFileToBucket(json_file_name)\n",
    "        print(f\"\\File uploaded to S3 bucket {json_file_name}.\")\n",
    "        \n",
    "        return True\n",
    "\n",
    "\n",
    "    #produces a joint-outliers result out of the five series\n",
    "    def produceJointResultOutOfAll(self, outliers1, outliers2, outliers3, outliers4, outliers5):\n",
    "        joint_outliers = []\n",
    "\n",
    "        #add your code here\n",
    "        # converting the arrays into sets\n",
    "        set_outliers_1 = set(outliers1)\n",
    "        set_outliers_2 = set(outliers2)\n",
    "        set_outliers_3 = set(outliers3)\n",
    "        set_outliers_4 = set(outliers4)\n",
    "        set_outliers_5 = set(outliers5)\n",
    "      \n",
    "        # Calculates the intersection of all outlier sets\n",
    "        joint_outliers_set = set_outliers_1.intersection(set_outliers_2, \n",
    "                                                         set_outliers_3, \n",
    "                                                         set_outliers_4, \n",
    "                                                         set_outliers_5)\n",
    "\n",
    "        # Converts the resulting set to a list\n",
    "        joint_outliers = list(joint_outliers_set)\n",
    " \n",
    "        return joint_outliers\n",
    "\n",
    "    #produces a joint outliers result out of a pair of series\n",
    "    def produceJointResultOutOfPair(self, outliers1, outliers2):\n",
    "        joint_outliers = []\n",
    "\n",
    "        # converting the arrays into sets\n",
    "        set_outliers_1 = set(outliers1)\n",
    "        set_outliers_2 = set(outliers2)\n",
    "        \n",
    "        # Calculates the intersection of all outlier sets\n",
    "        joint_outliers_set = set_outliers_1.intersection(set_outliers_2)\n",
    "\n",
    "        # Converts the resulting set to a list\n",
    "        joint_outliers = list(joint_outliers_set)\n",
    " \n",
    "        return joint_outliers\n",
    "\n",
    "\n",
    "    #executes an outliers detection phase\n",
    "    #possible phases:\n",
    "    # phase_1 - uses the provided CSV file to detect outliers\n",
    "    # phase_2 - uses the history rates extracted from CryptoCompare.com to detect outliers\n",
    "    # phase_3 - uses live-exchange rates provided from CryptoCompare.com to detect outliers\n",
    "    def executePhase(self, \n",
    "                     phase_num, \n",
    "                     series     # type Pandas Series\n",
    "                    ):\n",
    "\n",
    "        trial_num = 0\n",
    "        MAX_TRIALS = 2   # applies for phase 1 and phase 2\n",
    "        \n",
    "        while (True):\n",
    "            #add your code here\n",
    "        \n",
    "            print(f\"\\n{phase_num} - Trial #{trial_num + 1} of {MAX_TRIALS}..\")\n",
    "        \n",
    "            len_series = 0\n",
    "            if not series.empty:\n",
    "                len_series = len(series)\n",
    "            \n",
    "            print(\"Length of the series:\", len_series)\n",
    "\n",
    "            #step #1: exit on series size < 3\n",
    "            if len_series < 2:\n",
    "                print(\"Exiting, since series length < 3.\")\n",
    "                break\n",
    "  \n",
    "            #step #2: if series size > 100 then create a series of 100 elements selected at random from series\n",
    "            if len_series > 100:\n",
    "                print(\"Extracting 100 elements at random..\")\n",
    "                series = self.extract100ElementsAtRandom(series)    \n",
    "                len_series = len(series)\n",
    "                print(\"Updated length of the series:\", len_series)\n",
    "            \n",
    "            # series is type Pandas Series until here, here we convert to a Python list \n",
    "            # because this is type used in the methods supplied in the template code. However,\n",
    "            # we may convert these to Series later as it is more efficient.\n",
    "\n",
    "            # We now have a 100 element series\n",
    "            # Convert from Pandas Series to Python list for technique methods\n",
    " \n",
    "            values_100_list = series.tolist()\n",
    "            #print(f\"Converted to Python List of length: {len(values_100_list)}\")\n",
    "            \n",
    "            # step #2.5: Execute algorithms\n",
    "        \n",
    "            outliers_DQ = self.executeDixonQ(values_100_list)    \n",
    "            print(f\"Outliers DQ: {outliers_DQ}\")\n",
    "            outliers_StD = self.executeStandardDeviation(values_100_list)    \n",
    "            print(f\"Outliers StD: {outliers_StD}\")\n",
    "            outliers_IF = self.executeIsolationForest(values_100_list)    \n",
    "            print(f\"Outliers IF: {outliers_IF}\")\n",
    "            outliers_BXPLTS = self.executeBoxplots(values_100_list)    \n",
    "            print(f\"Outliers BXPLTS: {outliers_BXPLTS}\")\n",
    "            outliers_DBSCAN_CL = self.executeDBSCANClustering(values_100_list)    \n",
    "            print(f\"Outliers DBSCAN_CL: {outliers_DBSCAN_CL}\")\n",
    " \n",
    "            #step #3: joint_outliers_5 = \"joint outliers of all 5 algorithms\" \n",
    "            joint_outliers_5 = self.produceJointResultOutOfAll(outliers_DQ,\n",
    "                                                               outliers_StD,\n",
    "                                                               outliers_IF,\n",
    "                                                               outliers_BXPLTS,\n",
    "                                                               outliers_DBSCAN_CL)\n",
    "\n",
    "            print(f\"Joint outliers: {joint_outliers_5}\")\n",
    "            if (joint_outliers_5 is not None) and (len(joint_outliers_5) > 0):\n",
    "                \n",
    "                print(f\"SUCCESS - Found Joint outliers for all 5 methods!!!\")\n",
    "                print(f\"Here are joint outliers for all pairs of techniques...\")\n",
    "                \n",
    "                # joint outlier pairs \n",
    "                joint_outliers_DQ_StD = self.produceJointResultOutOfPair(outliers_DQ, outliers_StD)\n",
    "                print(f\"Outliers DQ_StD: {joint_outliers_DQ_StD}\")\n",
    "                joint_outliers_DQ_IF = self.produceJointResultOutOfPair(outliers_DQ, outliers_IF)\n",
    "                print(f\"Outliers DQ_IF: {joint_outliers_DQ_IF}\")\n",
    "                joint_outliers_DQ_BXPLTS = self.produceJointResultOutOfPair(outliers_DQ, outliers_BXPLTS)\n",
    "                print(f\"Outliers DQ_BXPLTS: {joint_outliers_DQ_BXPLTS}\")\n",
    "                joint_outliers_DQ_DBSCAN_CL = self.produceJointResultOutOfPair(outliers_DQ, outliers_DBSCAN_CL) \n",
    "                print(f\"Outliers DQ_DBSCAN_CL: {joint_outliers_DQ_DBSCAN_CL}\")\n",
    "                joint_outliers_StD_IF = self.produceJointResultOutOfPair(outliers_StD, outliers_IF)\n",
    "                print(f\"Outliers StD_IF: {joint_outliers_StD_IF}\")\n",
    "                joint_outliers_StD_BXPLTS = self.produceJointResultOutOfPair(outliers_StD, outliers_BXPLTS)\n",
    "                print(f\"Outliers StD_BXPLTS: {joint_outliers_StD_BXPLTS}\")\n",
    "                joint_outliers_StD_DBSCAN_CL = self.produceJointResultOutOfPair(outliers_StD, outliers_DBSCAN_CL)\n",
    "                print(f\"Outliers StD_DBSCAN_CL: {joint_outliers_StD_DBSCAN_CL}\")\n",
    "                joint_outliers_IF_BXPLTS = self.produceJointResultOutOfPair(outliers_IF, outliers_BXPLTS)\n",
    "                print(f\"Outliers IF_BXPLTS: {joint_outliers_IF_BXPLTS}\")\n",
    "                joint_outliers_IF_DBSCAN_CL = self.produceJointResultOutOfPair(outliers_IF, outliers_DBSCAN_CL) \n",
    "                print(f\"Outliers IF_DBSCAN_CL: {joint_outliers_IF_DBSCAN_CL}\")\n",
    "                joint_outliers_BXPLTS_DBSCAN_CL = self.produceJointResultOutOfPair(outliers_BXPLTS, outliers_DBSCAN_CL)\n",
    "                print(f\"Outliers BXPLTS_DBSCAN_CL: {joint_outliers_BXPLTS_DBSCAN_CL}\")\n",
    "                            \n",
    "                #step #4: self.produceJsonOutliers(arguments go here)            \n",
    "                json_file_name = f\"outliers_output_{phase_num}.json\"\n",
    "                self.produceJsonOutliers(json_file_name, \n",
    "                                         values_100_list,\n",
    "                                         outliers_DQ, \n",
    "                                         outliers_StD, \n",
    "                                         outliers_IF, \n",
    "                                         outliers_BXPLTS,\n",
    "                                         outliers_DBSCAN_CL,\n",
    "                                         joint_outliers_5,\n",
    "                                         joint_outliers_DQ_StD,\n",
    "                                         joint_outliers_DQ_IF,\n",
    "                                         joint_outliers_DQ_BXPLTS,\n",
    "                                         joint_outliers_DQ_DBSCAN_CL,\n",
    "                                         joint_outliers_StD_IF,\n",
    "                                         joint_outliers_StD_BXPLTS,\n",
    "                                         joint_outliers_StD_DBSCAN_CL,\n",
    "                                         joint_outliers_IF_BXPLTS,\n",
    "                                         joint_outliers_IF_DBSCAN_CL,\n",
    "                                         joint_outliers_BXPLTS_DBSCAN_CL)\n",
    "       \n",
    "                # found dataset with joint outliers for all 5\n",
    "                if phase_num == \"phase_3\":\n",
    "                    return True    # return to executeOnTimer() outer loop\n",
    "                else:\n",
    "                    break   \n",
    " \n",
    "            else:                \n",
    "                if phase_num == \"phase_3\":\n",
    "                    return False    # return to executeOnTimer() outer loop\n",
    "                else:\n",
    "                    print(f\"No joint outliers found: Attempt {trial_num + 1}.\")\n",
    "\n",
    "            trial_num += 1\n",
    "            if trial_num >= MAX_TRIALS:\n",
    "                print(f\"\\n{phase_num} - Max trials reached: {MAX_TRIALS}.\")\n",
    "                break\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "    #entry point for the one-shot execution\n",
    "    def execute(self, s3_df, crypto_currency):\n",
    "\n",
    "        #phase #1\n",
    "        print(\"\\nPhase 1\\n=======\")\n",
    "        series = self.extractSeriesFromDF(s3_df, crypto_currency)\n",
    "        print(f\"Retrieving Rates from S3 bucket...\\n{series}\")\n",
    "        assert isinstance(series, pd.Series), \"The variable 'series' is not a pandas Series\"\n",
    "        self.executePhase(\"phase_1\", series)\n",
    "\n",
    "        #phase #2\n",
    "        print(\"\\n\\nPhase 2\\n=======\")\n",
    "        series = self.extractSeriesFromCryptoCompare(crypto_currency)\n",
    "        print(f\"Retrieving Historical Rates from CryptoCompare.com...\\n{series}\")\n",
    "        assert isinstance(series, pd.Series), \"The variable 'series' is not a pandas Series\"\n",
    "        self.executePhase(\"phase_2\", series)\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "    #entry point for the time-based execution\n",
    "    def executeOnTimer(self, crypto_currency):\n",
    "\n",
    "        #phase #3\n",
    "        #series = []\n",
    "\n",
    "        #add your code here\n",
    "        TIMER_INTERVAL_SECS = 1\n",
    "        SERIES_SIZE = 5\n",
    "        trial_num = 0\n",
    "        \n",
    "        while True:\n",
    "            \n",
    "            # Start a trial...\n",
    "            print(f\"\\nTrial {trial_num + 1}...\")\n",
    "            \n",
    "            # Collect a series of live prices (100)\n",
    "            print(f\"Collecting {SERIES_SIZE} live prices from CryptoCompare.com ...\")\n",
    "            prices = []\n",
    "            for i in range(SERIES_SIZE):\n",
    "                cryptoCompare = CryptoCompareReader()\n",
    "                current_rate = cryptoCompare.readCurrentRate(crypto_currency)\n",
    "                #print(f\"Current Rate: {current_rate}\")\n",
    "                print(f\"{current_rate}\", end=\", \")\n",
    "                prices.append(current_rate)\n",
    "                # wait before collecting next live price\n",
    "                time.sleep(TIMER_INTERVAL_SECS)   \n",
    "            \n",
    "            # Convert from list to Series for executePhase()\n",
    "            series_100 = pd.Series(prices)\n",
    "            print(f\"\\nCollected {len(series_100)} live prices.\")\n",
    "            if self.executePhase(\"phase_3\", series_100):\n",
    "                break \n",
    "            \n",
    "            trial_num += 1\n",
    "\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e496463a",
   "metadata": {},
   "source": [
    "## Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "59a4853f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase 1\n",
      "=======\n",
      "Retrieving Rates from S3 bucket...\n",
      "5         111.415\n",
      "122       113.150\n",
      "136       113.280\n",
      "138       111.540\n",
      "144       111.650\n",
      "           ...   \n",
      "173733    111.790\n",
      "173738    124.940\n",
      "173741    187.510\n",
      "173782    137.750\n",
      "173790    179.130\n",
      "Name: offer, Length: 11371, dtype: float64\n",
      "\n",
      "phase_1 - Trial #1 of 2..\n",
      "Length of the series: 11371\n",
      "Extracting 100 elements at random..\n",
      "Updated length of the series: 100\n",
      "Executing DixonQ Enhanced Method...\n",
      "Shapiro-Wilk: Running Shapiro-Wilk test ....\n",
      "Shapiro-Wilk: Series does not look Gaussian\n",
      "DixonQ Test: Warning: Test should not be run on a series that is not normally distributed.\n",
      "Outliers DQ: {}\n",
      "Executing Standard Deviation Method...\n",
      "Outliers StD: []\n",
      "Executing Isolation Forest Method...\n",
      "Outliers IF: [85.825, 88.2, 88.6, 89.65, 90.09, 90.98, 99.42, 100.39, 104.19, 104.27, 105.35, 108.07, 109.71, 110.88, 111.9, 112.655, 113.41, 113.88, 114.01, 114.78, 114.93, 115.255, 135.37, 135.52, 136.02, 136.42, 137.865, 140.045, 140.21, 141.39, 141.91, 145.22, 148.94, 151.01, 151.78, 152.45, 169.12, 169.85, 178.4, 179.68, 179.91, 183.33, 184.31, 186.43, 187.8, 187.89, 191.18, 191.73, 191.74, 192.07, 195.43, 196.94, 203.89]\n",
      "Executing Boxplots Method...\n",
      "Outliers BXPLTS: []\n",
      "Executing DBScan Clustering Method...\n",
      "Outliers DBSCAN_CL: [85.825, 90.98, 96.05, 99.42, 100.39, 105.35, 108.07, 109.71, 111.9, 112.655, 137.865, 141.39, 141.91, 145.22, 145.92, 169.12, 169.85, 178.4, 183.33, 184.31, 186.43, 191.18, 195.43, 196.94, 203.89]\n",
      "Joint outliers: []\n",
      "No joint outliers found: Attempt 1.\n",
      "\n",
      "phase_1 - Trial #2 of 2..\n",
      "Length of the series: 100\n",
      "Executing DixonQ Enhanced Method...\n",
      "Shapiro-Wilk: Running Shapiro-Wilk test ....\n",
      "Shapiro-Wilk: Series does not look Gaussian\n",
      "DixonQ Test: Warning: Test should not be run on a series that is not normally distributed.\n",
      "Outliers DQ: {}\n",
      "Executing Standard Deviation Method...\n",
      "Outliers StD: []\n",
      "Executing Isolation Forest Method...\n",
      "Outliers IF: [85.825, 88.2, 88.6, 89.65, 90.09, 90.98, 93.54, 96.05, 98.17, 98.44, 99.42, 100.39, 104.19, 104.27, 105.35, 108.07, 109.71, 114.78, 114.93, 115.255, 135.37, 135.52, 136.02, 137.865, 141.39, 141.91, 145.22, 151.01, 151.305, 151.78, 152.45, 169.12, 169.85, 179.68, 179.91, 183.33, 184.31, 186.43, 187.8, 187.89, 191.18, 191.73, 191.74, 192.07, 195.43, 196.94, 203.89]\n",
      "Executing Boxplots Method...\n",
      "Outliers BXPLTS: []\n",
      "Executing DBScan Clustering Method...\n",
      "Outliers DBSCAN_CL: [85.825, 90.98, 96.05, 99.42, 100.39, 105.35, 108.07, 109.71, 111.9, 112.655, 137.865, 141.39, 141.91, 145.22, 145.92, 169.12, 169.85, 178.4, 183.33, 184.31, 186.43, 191.18, 195.43, 196.94, 203.89]\n",
      "Joint outliers: []\n",
      "No joint outliers found: Attempt 2.\n",
      "\n",
      "phase_1 - Max trials reached: 2.\n",
      "\n",
      "\n",
      "Phase 2\n",
      "=======\n",
      "Retrieving Historical Rates from CryptoCompare.com...\n",
      "0       32.63\n",
      "1       31.42\n",
      "2       30.69\n",
      "3       32.42\n",
      "4       33.66\n",
      "        ...  \n",
      "596    148.03\n",
      "597    142.15\n",
      "598    152.57\n",
      "599    146.03\n",
      "600    146.05\n",
      "Length: 601, dtype: float64\n",
      "\n",
      "phase_2 - Trial #1 of 2..\n",
      "Length of the series: 601\n",
      "Extracting 100 elements at random..\n",
      "Updated length of the series: 100\n",
      "Executing DixonQ Enhanced Method...\n",
      "Shapiro-Wilk: Running Shapiro-Wilk test ....\n",
      "Shapiro-Wilk: Series does not look Gaussian\n",
      "DixonQ Test: Warning: Test should not be run on a series that is not normally distributed.\n",
      "Outliers DQ: {}\n",
      "Executing Standard Deviation Method...\n",
      "Outliers StD: [183.79, 185.14, 189.67, 195.91, 202.43]\n",
      "Executing Isolation Forest Method...\n",
      "Outliers IF: [9.99, 11.33, 12.37, 34.95, 42.17, 56.6, 58.21, 59.28, 59.29, 61.01, 74.94, 91.0, 94.26, 95.42, 95.84, 103.47, 107.95, 108.42, 109.97, 110.4, 112.48, 117.11, 125.58, 143.73, 151.45, 152.57, 152.82, 174.46, 183.79, 185.14, 189.67, 195.91, 202.43]\n",
      "Executing Boxplots Method...\n",
      "Outliers BXPLTS: [125.58, 143.73, 151.45, 152.57, 152.82, 174.46, 183.79, 185.14, 189.67, 195.91, 202.43]\n",
      "Executing DBScan Clustering Method...\n",
      "Outliers DBSCAN_CL: [9.99, 11.33, 12.37, 26.7, 27.45, 34.95, 42.17, 56.6, 58.21, 61.01, 74.94, 91.0, 94.26, 103.47, 112.48, 117.11, 125.58, 143.73, 151.45, 174.46, 183.79, 185.14, 189.67, 195.91, 202.43]\n",
      "Joint outliers: []\n",
      "No joint outliers found: Attempt 1.\n",
      "\n",
      "phase_2 - Trial #2 of 2..\n",
      "Length of the series: 100\n",
      "Executing DixonQ Enhanced Method...\n",
      "Shapiro-Wilk: Running Shapiro-Wilk test ....\n",
      "Shapiro-Wilk: Series does not look Gaussian\n",
      "DixonQ Test: Warning: Test should not be run on a series that is not normally distributed.\n",
      "Outliers DQ: {}\n",
      "Executing Standard Deviation Method...\n",
      "Outliers StD: [183.79, 185.14, 189.67, 195.91, 202.43]\n",
      "Executing Isolation Forest Method...\n",
      "Outliers IF: [9.99, 11.33, 12.37, 34.95, 42.17, 56.6, 58.21, 59.28, 59.29, 61.01, 74.94, 91.0, 94.26, 95.42, 95.84, 103.47, 107.95, 108.42, 109.97, 110.4, 112.48, 117.11, 125.58, 143.73, 151.45, 152.57, 152.82, 174.46, 183.79, 185.14, 189.67, 195.91, 202.43]\n",
      "Executing Boxplots Method...\n",
      "Outliers BXPLTS: [125.58, 143.73, 151.45, 152.57, 152.82, 174.46, 183.79, 185.14, 189.67, 195.91, 202.43]\n",
      "Executing DBScan Clustering Method...\n",
      "Outliers DBSCAN_CL: [9.99, 11.33, 12.37, 26.7, 27.45, 34.95, 42.17, 56.6, 58.21, 61.01, 74.94, 91.0, 94.26, 103.47, 112.48, 117.11, 125.58, 143.73, 151.45, 174.46, 183.79, 185.14, 189.67, 195.91, 202.43]\n",
      "Joint outliers: []\n",
      "No joint outliers found: Attempt 2.\n",
      "\n",
      "phase_2 - Max trials reached: 2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assignment = CS6512Assignment2()\n",
    "assignment.execute(df, \"SOL\")\n",
    "#assignment.executeOnTimer(\"SOL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bdb1cf",
   "metadata": {
    "id": "36bdb1cf"
   },
   "source": [
    "### Pseudo code for executePhase() method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1936bcdc",
   "metadata": {
    "id": "1936bcdc"
   },
   "source": [
    "    def executePhase(self, phase_num, series):\n",
    "        while (True):\n",
    "            \n",
    "            #step #1: exit on series size < 3\n",
    "            \n",
    "            #step #2: if series size > 100 then create a series of 100 elements selected at random from series\n",
    "        \n",
    "            #step #3: joint_outliers_5 = \"joint outliers of all 5 algorithms\"      \n",
    "        \n",
    "            if \"joint_outliers_5\" is not empty:\n",
    "                #step #4: self.produceJsonOutliers(arguments go here)\n",
    "\n",
    "                break\n",
    "            \n",
    "            if phase_num == \"phase_3\":\n",
    "                break\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f1019c",
   "metadata": {
    "id": "69f1019c"
   },
   "source": [
    "### Pseudo code for executeOnTimer() method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4a092d",
   "metadata": {
    "id": "3a4a092d"
   },
   "source": [
    "    def executeOnEvent(self, crypto_currency):\n",
    "    \n",
    "        while (True):\n",
    "        \n",
    "            check if 30 seconds have elapsed:\n",
    "            \n",
    "                reset the timer\n",
    "       \n",
    "                #step #1: if the csv file with live-exchange cryptocurrency rates exists then load the rates from this file\n",
    "                       \n",
    "                #step #2: get the current live-exchange rate for crypto_currency by using the CryptoCompareReader class  \n",
    "        \n",
    "                #step #3: add live_rate to series\n",
    "        \n",
    "                #step #4: write the updated series into a csv file with live-exchange cryptocurrency rates\n",
    "                               \n",
    "                #step #5: self.executePhase(\"phase_3\", series)\n",
    "                    \n",
    "                break\n",
    "            \n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9b0b1c",
   "metadata": {
    "id": "5a9b0b1c"
   },
   "source": [
    "### The extract100ElementsAtRandom() method\n",
    "The Dixon Q works on series of elements with maximum size of 100 elements. Here if a series has a length larger than 100, we extract 100 elements at random. The 100-element series is processed by all the algorithms.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc67f734",
   "metadata": {
    "id": "bc67f734"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c8018d",
   "metadata": {
    "id": "72c8018d"
   },
   "source": [
    "You are required to test your solution with the <span style=\"color:blue\"><b>Solana</b></span> cryptocurrency (ticker = <span style=\"color:blue\"><b>'SOL'</b></span>). Solana is the fastest blockchain in the world and the fastest growing ecosystem in cryptocurrency. Hence, it may have quite volatile exchange rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb3353e",
   "metadata": {
    "id": "5fb3353e"
   },
   "source": [
    "## What to deliver?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c362e70",
   "metadata": {
    "id": "3c362e70"
   },
   "source": [
    "You are asked to deliver:\n",
    "<ul>\n",
    "<li>your solution: implemented in this notebook</li>\n",
    "<li>your result files: check the <b>results</b> directory to see the file names and their structure</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5a0d05",
   "metadata": {
    "id": "1a5a0d05"
   },
   "source": [
    "## A glimpse of your initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1de0914",
   "metadata": {
    "id": "a1de0914",
    "outputId": "74c57602-1d17-40c3-ecf3-80e76080b8e5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#df = pd.read_csv ('data\\instrument_price.csv') - original code\n",
    "#df = s3_client.readCsvFileFromBucket('instrument_price.csv') - run above\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a209541e",
   "metadata": {
    "id": "a209541e"
   },
   "outputs": [],
   "source": [
    "dfCurrency = df.loc[df['instrument_ticker'] == 'SOL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82908ed9",
   "metadata": {
    "id": "82908ed9",
    "outputId": "c62f09f6-949e-4c04-bce8-4b55025bba8b"
   },
   "outputs": [],
   "source": [
    "dfCurrency['offer'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25f8159",
   "metadata": {
    "id": "f25f8159"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56f6704b",
   "metadata": {},
   "source": [
    "## Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d27d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute(self, df, 'SOL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df97c084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
