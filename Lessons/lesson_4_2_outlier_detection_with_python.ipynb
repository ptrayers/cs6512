{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1239931",
   "metadata": {},
   "source": [
    "# Outlier Detection Techniques with Python\n",
    "\n",
    "by Emil Vassev\n",
    "\n",
    "April 3, 2022\n",
    "<br><br>\n",
    "Copyright (C) 2022 - All rights reserved, do not copy or distribute without permission of the author.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6172dec4",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Welcome to <b>Outlier Detection Techniques</b>, an interactive lecture designed to teach you not only how to recognize various techniques but also how to implement them correctly. This lecture provides both theoretical and practical knowledge.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6663186",
   "metadata": {},
   "source": [
    "## Definition of Outlier\n",
    "\"<i>In statistics, an outlier is a data point that differs significantly from other observations. An outlier may be due to variability in the measurement or it may indicate experimental error; the latter are sometimes excluded from the data set. An outlier can cause serious problems in statistical analyses.</i>\"<br> \n",
    "Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb8b701",
   "metadata": {},
   "source": [
    "## Algorithms for Detecting Outliers\n",
    "Three algorithms for detecting outliers are presented in this notebook:\n",
    "<li>Enhanced Dixon Q</li>\n",
    "<li>Mean & Standard Deviation</li>\n",
    "<li>Isolation Forest</li>\n",
    "\n",
    "These algorithms are meant to work individually on numerical datasets. However, we can combine these algorithms to produce a joint result based on the individual performance of all of the executed algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c612fdfd",
   "metadata": {},
   "source": [
    "Let's set the target series of numbers - we are going to detect outliers among these numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ce714bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = [100.625,96,122.873307,125.918466,126.5132685,87.640727,91.300919,\n",
    "          100.6596,119.999811,116.48158,117.9620459,118.7118,121.562339,\n",
    "          146.902942,141.993982,143.9881,142.135173,123.531172,133.782315,\n",
    "          126.077418,130.4194537,108.123033,113.338919,106.6014,109.593951,\n",
    "          126.97778,126.550827,128.7285245,130.6084,130.799433,100.340734,\n",
    "          106.584198,197.4606,79.782605,167.574109,169.114286,159.2281,\n",
    "          77.141509,75.671004,110.84316,112.30969,117.942093,63,65,60,\n",
    "          130.703856,119.597655,141.648019,145.018004,142.8685393,145.6221,\n",
    "          145.503622,97.600952,92,103.824548,123.521852,112.409556,110.995964,\n",
    "          122.25,94.931864,104.851577,108.4738,134.262473,99.746662,99.8667,\n",
    "          76.813091,72.5126,117.665167,120.103798,121.5737367,118.1471,\n",
    "          126.588321,142.899425,136.782077,115.963214,124.339492,156.476319,\n",
    "          169.429444,172.353,164.957759,63,64,40,111.977501,114.672941,\n",
    "          118.0479,115.514796,105.948,88.050064,111.848821,108.69286,\n",
    "          108.056866,110.125964,97.1435,110.399885,126.046539,125.154034,\n",
    "          128.575127]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d3acbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>116.713784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>26.780257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>104.081305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>117.952069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>129.996721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>197.460600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             test\n",
       "count   98.000000\n",
       "mean   116.713784\n",
       "std     26.780257\n",
       "min     40.000000\n",
       "25%    104.081305\n",
       "50%    117.952069\n",
       "75%    129.996721\n",
       "max    197.460600"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'test':series})\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62f87541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['test'].plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e72881",
   "metadata": {},
   "source": [
    "## Dixon Q Outlier Detector - Enhanced Dixon Q Test\n",
    "author's implementation by Emil Vassev\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9271df11",
   "metadata": {},
   "source": [
    "Dixon Q Test is an outlier detection test that usually operates on small, normally distributed, datasets. Small datasets are usually defined as somewhere between 3 and 7 items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdb0d4c",
   "metadata": {},
   "source": [
    "### New Enhanced Version of Dixon Q Outlier Test\n",
    "The implementation of new Enhanced Dixon Q Test for Outliers was motivated by a few important reasons:  \n",
    "<br>\n",
    "The widely spread implementations of this outlier detection test:\n",
    "<li>use critical values with 3 decimal places, thus having an impact on the algorithm accuracy</li>\n",
    "<li>are unable to handle data sets larger than 30 samples</li>\n",
    "<li>are unable to handle some cases with obvious outliers</li> \n",
    "<li>are often wrongly implemented</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a2403e",
   "metadata": {},
   "source": [
    "### New Critical Values\n",
    "Any Dixon Q Test is using a table of critical values (or <b>Q Table</b>) used to discover outliers. As part of the R&D of the new Enhanced Dixon Q Test, a computation of new critical values for Dixon discordance tests has been done: 1) initially, by using <i>Monte Carlo simulations</i>; and then 2) by generating missing values through a standard deviation technique. With this new <b>Q Table</b>, the new Enhanced Dixon Q Test is able to: \n",
    "<li>process data sets of up to 100 samples</li>\n",
    "<li>provide a full spectrum of levels of confidence varying from 70% up to 99.5%</li> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d34613",
   "metadata": {},
   "source": [
    "### Implementation of Enhanced Dixon Q Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "083bc722",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Enhanced Dixon Q Test\n",
    "\n",
    "@author: Emil Vassev\n",
    "\"\"\"\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "\"\"\"\n",
    " *\n",
    " * This class implements an enhanced version of DixonQ Test.\n",
    " * Provides a set of encoded critical values - up to 100.\n",
    " * The encoded critical values are used as a basis to generate critical values for other alphas (levels of confidence).\n",
    " * Both encoded and generated critical values are used to produce a result of maximum accuracy when identifying outliers. \n",
    " *  \n",
    "\"\"\" \n",
    "class DixonQEnhanced:\n",
    "    \n",
    "    criticalValues = {}\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     * DixonQEnhanced constructor\n",
    "    \"\"\" \n",
    "    def __init__(self):\n",
    "        self.buildCriticalValues()\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     * Builds a dictionary of critical values grouped by alpha  \n",
    "    \"\"\"\n",
    "    def buildCriticalValues(self):\n",
    "        \n",
    "        \"\"\"\n",
    "         * the critical values are grouped by an alpha key\n",
    "         * alpha is the probability of incorrectly rejecting the suspected outlier\n",
    "        \"\"\"    \n",
    "        #encoded critical values for alpha = 0.3 (0.7% level of confidence)\n",
    "        self.criticalValues[0.30] = [0,0,\n",
    "                                     0.6836,0.4704,0.3730,0.3173,0.2811,0.2550,0.2361,0.2208,\n",
    "                                     0.2086,0.1983,0.1898,0.1826,0.1764,0.1707,0.1656,0.1613,\n",
    "                                     0.1572,0.1535,0.1504,0.1474,0.1446,0.1420,0.1397,0.1376,\n",
    "                                     0.1355,0.1335,0.1318,0.1300,0.1283,0.1268,0.1255,0.1240,\n",
    "                                     0.1227,0.1215,0.1202,0.1192,0.1181,0.1169,0.1160,0.1153,\n",
    "                                     0.1141,0.1134,0.1124,0.1116,0.1108,0.1102,0.1093,0.1087,\n",
    "                                     0.1079,0.1071,0.1067,0.1060,0.1052,0.1047,0.1041,0.1036,\n",
    "                                     0.1030,0.1024,0.1019,0.1014,0.1009,0.1004,0.1000,0.0997,\n",
    "                                     0.0991,0.0987,0.0982,0.0979,0.0974,0.0970,0.0967,0.0961,\n",
    "                                     0.0960,0.0955,0.0952,0.0948,0.0943,0.0939,0.0937,0.0935,\n",
    "                                     0.0930,0.0928,0.0925,0.0921,0.0918,0.0915,0.0913,0.0910,\n",
    "                                     0.0906,0.0903,0.0902,0.0899,0.0896,0.0894,0.0892,0.0890,\n",
    "                                     0.0887,0.0885]\n",
    "        \n",
    "        #encoded critical values for alpha = 0.2 (0.8% level of confidence)\n",
    "        self.criticalValues[0.20] = [0,0,\n",
    "                                     0.7808,0.5603,0.4508,0.3868,0.3444,0.3138,0.2915,0.2735,\n",
    "                                     0.2586,0.2467,0.2366,0.2280,0.2202,0.2137,0.2077,0.2023,\n",
    "                                     0.1973,0.1929,0.1890,0.1854,0.1820,0.1790,0.1761,0.1735,\n",
    "                                     0.1710,0.1687,0.1664,0.1645,0.1624,0.1604,0.1590,0.1571,\n",
    "                                     0.1555,0.1540,0.1525,0.1512,0.1499,0.1484,0.1472,0.1462,\n",
    "                                     0.1449,0.1441,0.1430,0.1418,0.1408,0.1400,0.1390,0.1381,\n",
    "                                     0.1374,0.1365,0.1357,0.1349,0.1340,0.1334,0.1326,0.1320,\n",
    "                                     0.1312,0.1304,0.1299,0.1294,0.1286,0.1281,0.1275,0.1272,\n",
    "                                     0.1264,0.1260,0.1254,0.1249,0.1243,0.1238,0.1234,0.1228,\n",
    "                                     0.1225,0.1221,0.1217,0.1212,0.1205,0.1201,0.1198,0.1195,\n",
    "                                     0.1189,0.1187,0.1182,0.1178,0.1174,0.1171,0.1167,0.1165,\n",
    "                                     0.1160,0.1156,0.1154,0.1151,0.1147,0.1144,0.1141,0.1138,\n",
    "                                     0.1134,0.1131]        \n",
    "\n",
    "        #encoded critical values for alpha = 0.1 (0.9% level of confidence)\n",
    "        self.criticalValues[0.10] = [0,0,\n",
    "                                     0.8850,0.6789,0.5578,0.4840,0.4340,0.3979,0.3704,0.3492,\n",
    "                                     0.3312,0.3170,0.3045,0.2938,0.2848,0.2765,0.2691,0.2626,\n",
    "                                     0.2564,0.2511,0.2460,0.2415,0.2377,0.2337,0.2303,0.2269,\n",
    "                                     0.2237,0.2208,0.2182,0.2155,0.2132,0.2110,0.2088,0.2066,\n",
    "                                     0.2045,0.2026,0.2008,0.1993,0.1974,0.1958,0.1944,0.1930,\n",
    "                                     0.1915,0.1902,0.1890,0.1875,0.1865,0.1850,0.1839,0.1829,\n",
    "                                     0.1819,0.1808,0.1797,0.1788,0.1777,0.1768,0.1759,0.1752,\n",
    "                                     0.1741,0.1733,0.1726,0.1717,0.1707,0.1703,0.1694,0.1689,\n",
    "                                     0.1679,0.1674,0.1667,0.1660,0.1652,0.1648,0.1641,0.1635,\n",
    "                                     0.1631,0.1626,0.1620,0.1613,0.1605,0.1601,0.1596,0.1594,\n",
    "                                     0.1586,0.1583,0.1576,0.1573,0.1567,0.1563,0.1557,0.1554,\n",
    "                                     0.1547,0.1544,0.1540,0.1537,0.1532,0.1528,0.1524,0.1521,\n",
    "                                     0.1516,0.1512]        \n",
    "\n",
    "        #encoded critical values for alpha = 0.05 (0.95% level of confidence)\n",
    "        self.criticalValues[0.05] = [0,0,\n",
    "                                     0.9411,0.7651,0.6423,0.5624,0.5077,0.4673,0.4363,0.4122,\n",
    "                                     0.3922,0.3755,0.3615,0.3496,0.3389,0.3293,0.3208,0.3135,\n",
    "                                     0.3068,0.3005,0.2947,0.2895,0.2851,0.2804,0.2763,0.2725,\n",
    "                                     0.2686,0.2655,0.2622,0.2594,0.2567,0.2541,0.2513,0.2488,\n",
    "                                     0.2467,0.2445,0.2423,0.2408,0.2383,0.2366,0.2350,0.2334,\n",
    "                                     0.2319,0.2302,0.2288,0.2273,0.2257,0.2241,0.2228,0.2216,\n",
    "                                     0.2206,0.2191,0.2182,0.2169,0.2160,0.2145,0.2135,0.2126,\n",
    "                                     0.2116,0.2106,0.2095,0.2085,0.2075,0.2070,0.2057,0.2053,\n",
    "                                     0.2045,0.2037,0.2030,0.2020,0.2013,0.2005,0.1996,0.1990,\n",
    "                                     0.1984,0.1980,0.1973,0.1964,0.1955,0.1950,0.1943,0.1940,\n",
    "                                     0.1934,0.1927,0.1922,0.1918,0.1909,0.1906,0.1899,0.1896,\n",
    "                                     0.1887,0.1885,0.1881,0.1876,0.1869,0.1865,0.1860,0.1856,\n",
    "                                     0.1851,0.1846]        \n",
    "\n",
    "        #encoded critical values for alpha = 0.02 (0.98% level of confidence)\n",
    "        self.criticalValues[0.02] = [0,0,\n",
    "                                     0.9763,0.8457,0.7291,0.6458,0.5864,0.5432,0.5091,0.4813,\n",
    "                                     0.4591,0.4405,0.4250,0.4118,0.3991,0.3883,0.3792,0.3711,\n",
    "                                     0.3630,0.3562,0.3495,0.3439,0.3384,0.3328,0.3287,0.3242,\n",
    "                                     0.3202,0.3163,0.3127,0.3093,0.3060,0.3036,0.2999,0.2973,\n",
    "                                     0.2948,0.2921,0.2898,0.2879,0.2853,0.2836,0.2815,0.2794,\n",
    "                                     0.2778,0.2758,0.2744,0.2726,0.2711,0.2690,0.2676,0.2662,\n",
    "                                     0.2651,0.2632,0.2620,0.2606,0.2595,0.2582,0.2570,0.2555,\n",
    "                                     0.2545,0.2531,0.2522,0.2510,0.2500,0.2493,0.2480,0.2472,\n",
    "                                     0.2466,0.2457,0.2445,0.2436,0.2429,0.2420,0.2409,0.2402,\n",
    "                                     0.2398,0.2387,0.2382,0.2372,0.2365,0.2360,0.2349,0.2345,\n",
    "                                     0.2337,0.2330,0.2322,0.2319,0.2309,0.2304,0.2298,0.2294,\n",
    "                                     0.2285,0.2279,0.2272,0.2272,0.2259,0.2257,0.2251,0.2247,\n",
    "                                     0.2240,0.2234]        \n",
    "\n",
    "        #encoded critical values for alpha = 0.01 (0.99% level of confidence)\n",
    "        self.criticalValues[0.01] = [0,0,\n",
    "                                     0.9881,0.8886,0.7819,0.6987,0.6371,0.5914,0.5554,0.5260,\n",
    "                                     0.5028,0.4831,0.4664,0.4517,0.4385,0.4268,0.4166,0.4081,\n",
    "                                     0.4002,0.3922,0.3854,0.3789,0.3740,0.3674,0.3625,0.3583,\n",
    "                                     0.3543,0.3499,0.3460,0.3425,0.3390,0.3357,0.3323,0.3294,\n",
    "                                     0.3266,0.3238,0.3213,0.3187,0.3163,0.3141,0.3124,0.3102,\n",
    "                                     0.3081,0.3061,0.3050,0.3028,0.3009,0.2991,0.2972,0.2960,\n",
    "                                     0.2941,0.2927,0.2920,0.2899,0.2880,0.2873,0.2859,0.2845,\n",
    "                                     0.2828,0.2816,0.2812,0.2792,0.2784,0.2775,0.2766,0.2754,\n",
    "                                     0.2742,0.2735,0.2724,0.2714,0.2709,0.2696,0.2682,0.2677,\n",
    "                                     0.2667,0.2662,0.2656,0.2646,0.2637,0.2633,0.2621,0.2614,\n",
    "                                     0.2608,0.2599,0.2588,0.2584,0.2573,0.2568,0.2566,0.2558,\n",
    "                                     0.2548,0.2543,0.2539,0.2535,0.2524,0.2521,0.2512,0.2513,\n",
    "                                     0.2499,0.2498]   \n",
    "        \n",
    "        #encoded critical values for alpha = 0.005 (0.995% level of confidence)\n",
    "        self.criticalValues[0.005] = [0,0,\n",
    "                                     0.9940,0.9201,0.8234,0.7437,0.6809,0.6336,0.5952,0.5668,\n",
    "                                     0.5416,0.5208,0.5034,0.4869,0.4739,0.4614,0.4504,0.4423,\n",
    "                                     0.4333,0.4247,0.4173,0.4109,0.4051,0.3986,0.3935,0.3889,\n",
    "                                     0.3843,0.3801,0.3762,0.3718,0.3685,0.3646,0.3610,0.3583,\n",
    "                                     0.3548,0.3522,0.3498,0.3465,0.3443,0.3415,0.3400,0.3377,\n",
    "                                     0.3353,0.3332,0.3325,0.3298,0.3279,0.3256,0.3235,0.3225,\n",
    "                                     0.3204,0.3191,0.3177,0.3163,0.3140,0.3136,0.3118,0.3098,\n",
    "                                     0.3089,0.3075,0.3071,0.3061,0.3041,0.3031,0.3025,0.3006,\n",
    "                                     0.2996,0.2990,0.2983,0.2968,0.2959,0.2946,0.2934,0.2932,\n",
    "                                     0.2922,0.2912,0.2905,0.2897,0.2885,0.2876,0.2870,0.2859,\n",
    "                                     0.2852,0.2844,0.2836,0.2832,0.2818,0.2811,0.2808,0.2798,\n",
    "                                     0.2790,0.2788,0.2784,0.2775,0.2766,0.2764,0.2755,0.2751,\n",
    "                                     0.2738,0.2737]   \n",
    "\n",
    "        \"\"\"\n",
    "         * Generates all critical values by using the encoded values as a basis.\n",
    "         * Values are genereated between any two existing pairs of alphas.\n",
    "        \"\"\" \n",
    "        #generate range alpha 0.2 - 0.1\n",
    "        self.generateCriticalValuesForAlphaPair(0.2,0.1)\n",
    "\n",
    "        #generate range alpha 0.3 - 0.2\n",
    "        self.generateCriticalValuesForAlphaPair(0.3,0.2)\n",
    "\n",
    "        #generate range alpha 0.10 - 0.05\n",
    "        self.generateCriticalValuesForAlphaPair(0.10,0.05)\n",
    "\n",
    "        #generate range alpha 0.05 - 0.02\n",
    "        self.generateCriticalValuesForAlphaPair(0.05,0.02)\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "     * Generates the missing series of critical values between two alphas with a step = 0.01\n",
    "     * constraint: alpha1 > alpha2\n",
    "    \"\"\" \n",
    "    def generateCriticalValuesForAlphaPair(self, alpha1, alpha2):\n",
    "        \n",
    "        if alpha1 < alpha2:\n",
    "            raise Exception('The value of alpha1 is less than alpha2.')\n",
    "            \n",
    "        nInsideAlphas = int(round((alpha1 - alpha2)/(0.01)) - 1)\n",
    "        \n",
    "        insideAlphas = []\n",
    "        \n",
    "        step = 0.01\n",
    "        for i in range(1,nInsideAlphas+1):\n",
    "            newAlpha = round(alpha2 + i*step,2)\n",
    "            insideAlphas.append(newAlpha) \n",
    "        \n",
    "        for index in range(2,100):\n",
    "\n",
    "            rangeLeft = self.criticalValues[alpha1][index]\n",
    "            rangeRight = self.criticalValues[alpha2][index]\n",
    "        \n",
    "            distance = round(((rangeRight - rangeLeft)/(nInsideAlphas+1)),4)\n",
    "            \n",
    "            currentValue = self.criticalValues[alpha1][index]\n",
    "            \n",
    "            for insideAlpha in insideAlphas:\n",
    "                \n",
    "                if insideAlpha not in self.criticalValues.keys():\n",
    "                    self.criticalValues[insideAlpha] = []\n",
    "                    self.criticalValues[insideAlpha].append(0)\n",
    "                    self.criticalValues[insideAlpha].append(0)\n",
    "                \n",
    "                currentValue += distance\n",
    "                \n",
    "                currentValue = round(currentValue,4)\n",
    "                \n",
    "                self.criticalValues[insideAlpha].append(currentValue)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50270d6",
   "metadata": {},
   "source": [
    "### Correct Implementation\n",
    "Every implementation of the Dixon Q Test is bounded to the computation of a Q exponential value by using the original formula (called R10), or simply the “Q” formula:\n",
    "<br>\n",
    "![title](images/r10.png)\n",
    "<br>\n",
    "Where:\n",
    "<li>$x_{k}$ is the number that is under evaluation, i.e., an eventual candidate for outlier</li>   \n",
    "<li>$x_{(k±1})$ is the number nearest to $x_{k}$, i.e., the number of the left or the right side</li>\n",
    "<li>$x_{1}$ is the smallest value of the series</li>\n",
    "<li>$x_{n}$ is the largest value of the series</li>\n",
    "\n",
    "Once computed the $Q_{exp}$ value, the latter is compared to the critical value (from the Q Table) that corresponds to the sample size. Here, for a sample size of 7 numbers (n=7), the 7th Q critical value in the Q Table is picked up. Note that the Q critical value is picked up in multiple iterations where each iteration examines a different level of confidence. Finally, $Q_{exp}$ is compared with the Q critical value and if $Q_{exp}$ is greater than the Q critical value, the point is considered to be an outlier.\n",
    "\n",
    "Note that in the Internet space, there are many wrong interpretations of the R10 formula, i.e.:\n",
    "<br>\n",
    "![title](images/r10_wrong.png)\n",
    "<br>\n",
    "The Enhanced Dixon Q Test is strictly bounded to the correct interpretation of R10 and in this implementation $Q_{exp}$ is compared against the new Q Table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b8acc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DixonQEnhanced(DixonQEnhanced):    \n",
    "    \"\"\"\n",
    "     * Finds the next element in a series of elements\n",
    "    \"\"\"\n",
    "    def findNextInSeries(self, number, series):\n",
    "        \n",
    "        result = -1\n",
    "        \n",
    "        try:\n",
    "            index = series.index(number)\n",
    "        except ValueError as e:\n",
    "            raise Exception('The number has not been found in the series.')\n",
    "\n",
    "        if index == (len(series) - 1):\n",
    "            result = index - 1\n",
    "        else:\n",
    "            result = index + 1\n",
    "\n",
    "        return result\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "     * Finds the previous element in a series of elements\n",
    "    \"\"\"\n",
    "    def findPreviousInSeries(self, number, series):\n",
    "        \n",
    "        result = -1\n",
    "        \n",
    "        try:\n",
    "            index = series.index(number)\n",
    "        except ValueError as e:\n",
    "            raise Exception('The number has not been found in the series.')\n",
    "\n",
    "        if index == 0:\n",
    "            result = index + 1\n",
    "        else:\n",
    "            result = index - 1\n",
    "\n",
    "        return result\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "     * Identifies if a number is outlier within a series and for particular alpha\n",
    "    \"\"\"\n",
    "    def isOutlier(self, number, series, alpha):\n",
    "                \n",
    "        qCritical = 0.0\n",
    "        \n",
    "        qExpDivisor = series[len(series)-1] - series[0]\n",
    "        \n",
    "        if qExpDivisor == 0:\n",
    "            return False\n",
    "        \n",
    "        if len(series) > 100:\n",
    "            return False\n",
    "\n",
    "        nextNumberGap = abs(number - series[self.findNextInSeries(number,series)])\n",
    "        prevNumberGap = abs(number - series[self.findPreviousInSeries(number,series)])\n",
    "        if prevNumberGap < nextNumberGap:\n",
    "            closestNumberGap = prevNumberGap\n",
    "        else:\n",
    "            closestNumberGap = nextNumberGap\n",
    "            \n",
    "        qExp = closestNumberGap/qExpDivisor\n",
    "        \n",
    "        if alpha in self.criticalValues.keys():\n",
    "            qCritical = self.criticalValues[alpha][len(series)-1]\n",
    "            \n",
    "        if qExp > qCritical:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "     * Identifies all the outliers within a series\n",
    "     * Uses the isOutlier method\n",
    "    \"\"\"\n",
    "    def findOutliers(self, series):\n",
    "        \n",
    "        outliers = {}\n",
    "        \n",
    "        for alpha in self.criticalValues.keys():            \n",
    "            for number in series:\n",
    "                if self.isOutlier(number,series,alpha):\n",
    "                    if number in outliers:\n",
    "                        if outliers[number] < (1-alpha):\n",
    "                            outliers[number] = (1-alpha)\n",
    "                    else:\n",
    "                        outliers[number] = (1-alpha)\n",
    "                        \n",
    "        return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca9f8f5",
   "metadata": {},
   "source": [
    "### The Normal Distribution Requirement\n",
    "The Dixon Q Test is based on the statistical distribution of \"sub-range ratios\" of ordered data samples, drawn from the same normal population. Hence, a normal (Gaussian) distribution of data is assumed whenever this test is applied. This basically means that the Dixon Q Test should not be run on a series of numbers, which are not distributed normally. A normal distribution, sometimes called the bell curve, is a distribution where the corresponding curve is symmetrical, i.e., half of the data will fall to the left of the mean and half will fall to the right (see Figure below).\n",
    "<br>\n",
    "![title](images/gaussian_distribution.png)\n",
    "<br>\n",
    "As part of its implementation, the Enhanced Dixon Q Test runs a Shapiro-Wilk Test for normality on each series that is to be processed for outliers. Note that the Shapiro-Wilk Test for normality is one of three general normality tests designed to detect departures from normality.  In general, the test rejects the hypothesis of normality when the result (a special p-value) is less than or equal to 0.05. Failing the normality test allows you to state with 95% confidence that the data does not fit in a normal distribution.  Passing the normality test only allows us to state that no significant departure from normality has been detected. \n",
    "\n",
    "The implementation of the Shapiro-Wilk Test is based on the following formula: \n",
    "<br>\n",
    "![title](images/shapiro_wilk.png)\n",
    "<br>\n",
    "where $x_{(1)}$ ≤ $x_{(2)}$ ≤ ••• ≤ $x_{(n)}$ are the ordered values of a sample $x_{1}$, $x_{2}$, ..., $x_{n}$, and $a_{i}$ are tabulated coefficients. A lower tail of $W$ indicates non-normality.\n",
    "\n",
    "When we use the Enhanced Dixon Q Test for detecting outliers, we work on a finite set of numbers, which is generated by a business process that is a subject to upsets and changes over time, and therefore, it might not have a normal histogram. As a result, the Enhanced Dixon Q Test will produce approximate evaluation that might not be satisfactory. Hence, an important step in data analysis is to inspect the distribution of the observations. Rather than assuming a normal distribution and estimating the mean and variance, we shall estimate the complete distribution of the data.\n",
    "\n",
    "To conform with this requirement, the Enhanced Dixon Q Test, checks if the series of numbers is normally distributed and issues a warning if it is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d173d862",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DixonQEnhanced(DixonQEnhanced):    \n",
    "    \"\"\"\n",
    "     * Checks if the data set is normally distributed;\n",
    "     * running DixonQ Test on different distributions will lead to erroneous results\n",
    "     *\n",
    "     * Runs a Shapiro-Wilk test to check if the series is Gaussian\n",
    "    \"\"\"    \n",
    "    def checkForNormalDisribution(self, series):\n",
    "        \n",
    "        print(\"Shapiro-Wilk: Running Shapiro-Wilk test ....\")\n",
    "        \n",
    "        stat, p = shapiro(series)\n",
    "        \n",
    "        alpha = 0.05\n",
    "        \n",
    "        if p > alpha:       \n",
    "            print(\"Shapiro-Wilk: Series looks Gaussian\")\n",
    "            print(\"\")\n",
    "            return True\n",
    "\n",
    "        else:\n",
    "            print(\"Shapiro-Wilk: Series does not look Gaussian\")\n",
    "            print(\"\")\n",
    "            return False\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "     * Executes DixonQ Test on the provided series of numbers;\n",
    "     * DixonQ Test is executed for all available alpha keys (levels of confidence)\n",
    "    \"\"\" \n",
    "    def execute(self, series):\n",
    "        \n",
    "        outliers = {}\n",
    "\n",
    "        series.sort(reverse=False)\n",
    "        \n",
    "        if not self.checkForNormalDisribution(series):\n",
    "            print(\"DixonQ Test: Warning: Test should not be run on a series that is not normally distributed.\")\n",
    "\n",
    "        outliers = self.findOutliers(series)\n",
    "        \n",
    "        return outliers        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfb2b70",
   "metadata": {},
   "source": [
    "### Execution of Enhanced Dixon Q Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bfb0f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro-Wilk: Running Shapiro-Wilk test ....\n",
      "Shapiro-Wilk: Series looks Gaussian\n",
      "\n",
      "{40: 0.89, 197.4606: 0.94}\n",
      "[40, 197.4606]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    " * Executes the DixonQ Test\n",
    "\"\"\"\n",
    "dixonQEnhanced = DixonQEnhanced()\n",
    "outliers_dixon_q = dixonQEnhanced.execute(series)\n",
    "\n",
    "print(outliers_dixon_q)\n",
    "\n",
    "outliers_dixon_q = list(outliers_dixon_q.keys())\n",
    "\n",
    "print(outliers_dixon_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d2e681",
   "metadata": {},
   "source": [
    "## Mean & Standard Deviation Method\n",
    "author's implementation by Emil Vassev\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0e9ae9",
   "metadata": {},
   "source": [
    "Standard deviation is a metric of variance, i.e., it shows how much the individual data points are spread out from the mean as shown by the Figure below (Wikipedia).\n",
    "<br>\n",
    "![standard deviation](images/standard_deviation_small.png)\n",
    "<br>\n",
    "In this outlier detection method, the mean and standard deviation of the numbers are calculated and compared. If a value is a certain number of standard deviations away from the mean, then that data point is identified as an outlier. The specified number of standard deviations is considered to be a <b>threshold</b>. The default threshold value is 3 (three)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ed3ae8",
   "metadata": {},
   "source": [
    "### Implementation of Mean & Standard Deviation Method\n",
    "As part of this exercise, a number of experiments have been conducted to calibrate the Mean & Standard Deviation algorithm’s threshold. Experiments have been done with threshold values of 1.5, 1.75, 2, 2.5, and 3. The conclusion is that when running this algorithm in conjunction with the Enhanced Dixon Q algorithm, the 2.5 threshold appears to be the one that synchronizes both algorithms very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77b4cd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\"\"\"\n",
    " * This class implements the Standard Deviation Method for detecting outliers\n",
    "\"\"\"\n",
    "class StandardDeviationMethod:\n",
    "    \n",
    "    \n",
    "    methodName = \"StandardDeviationMethod\"\n",
    "    \n",
    "    upperLimit = 0.0\n",
    "    lowerLimit = 0.0\n",
    "    seriesStd = 0.0\n",
    "    seriesMean = 0.0\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\" \n",
    "    def __init__(self):\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\" \n",
    "    def getMethodName(self):\n",
    "        return \"Standard Deviation Method\"\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "     * Function to detect outliers on one-dimentional datasets\n",
    "    \"\"\"\n",
    "    def execute(self, series):\n",
    "        \n",
    "        outliers = []\n",
    "    \n",
    "        # set upper and lower limits to 3 times the standard deviation\n",
    "        seriesStd = np.std(series)\n",
    "        seriesMean = np.mean(series)\n",
    "        #anomalyCutOff = seriesStd * 3\n",
    "        #anomalyCutOff = seriesStd * 2\n",
    "        #anomalyCutOff = seriesStd * 1.5\n",
    "        #anomalyCutOff = seriesStd * 1.75\n",
    "        anomalyCutOff = seriesStd * 2.5\n",
    "        \n",
    "        lowerLimit  = seriesMean - anomalyCutOff \n",
    "        upperLimit = seriesMean + anomalyCutOff\n",
    "        \n",
    "        #print(lowerLimit)\n",
    "        \n",
    "        self.upperLimit = upperLimit\n",
    "        self.lowerLimit = lowerLimit\n",
    "        self.seriesStd = seriesStd\n",
    "        self.seriesMean = seriesMean\n",
    "\n",
    "        # generate outliers\n",
    "        for outlier in series:\n",
    "            if outlier > upperLimit or outlier < lowerLimit:\n",
    "                outliers.append(outlier)\n",
    "                \n",
    "        return outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4ec4e0",
   "metadata": {},
   "source": [
    "### Execution of Mean & Standard Deviation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db3c0a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 197.4606]\n"
     ]
    }
   ],
   "source": [
    "standardDeviationMethod = StandardDeviationMethod()\n",
    "\n",
    "outliers_standard_deviation = standardDeviationMethod.execute(series)\n",
    "\n",
    "print(outliers_standard_deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f121c2",
   "metadata": {},
   "source": [
    "## Isolation Forest Method\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d12ff9",
   "metadata": {},
   "source": [
    "The Isolation Forest algorithm explicitly identifies anomalies instead of profiling normal data points. This algorithm is a tree ensemble method that is built on the basis of decision trees. In these trees, partitions are created by first randomly selecting a feature and then selecting a random split value between the minimum and maximum value of the selected feature.\n",
    "The idea of identifying a normal vs. abnormal observation can be observed in the following Figure. A normal point (on the left) requires more partitions to be identified than an abnormal point (on the right).\n",
    "<br>\n",
    "![title](images/isolation_forest.png)\n",
    "<br>\n",
    "As with other outlier detection methods, an anomaly score is required for decision making. In the case of Isolation Forest, it is defined as:\n",
    "<br>\n",
    "![title](images/isolation_forest_alg.png)\n",
    "<br>\n",
    "where $h(x)$ is the path length of observation $x$, $c(n)$ is the average path length of unsuccessful search in a Binary Search Tree and $n$ is the number of external nodes. \n",
    "\n",
    "Each observation is given an anomaly score and a decision is made based on the following rules:\n",
    "<li>a score close to 1 indicates anomalies</li>\n",
    "<li>score much smaller than 0.5 indicates normal observations</li>\n",
    "<li>if all scores are close to 0.5 then the entire sample does not seem to have clearly distinct anomalies</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5660b7a7",
   "metadata": {},
   "source": [
    "### Implementation of Isolation Forest Method\n",
    "As part of this exercise, the Isolation Forest algorithm has been implemented and run by using the <i>sklearn.ensemble</i> package. Although this algorithm copes well with the human perception of outliers, e.g., numbers that fall outside the dense area, it has appeared to be quite slow. This low speed performance is most probably due to the partitioning and costly estimation of the path lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b060953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    " * This class implements the Isolation Forest Method for detecting outliers\n",
    "\"\"\"\n",
    "class IsolationForestMethod:\n",
    "\n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\" \n",
    "    def __init__(self):       \n",
    "        pass\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "     *\n",
    "    \"\"\" \n",
    "    def checkAllElementsEqual(self, series):\n",
    "        return len(set(series)) <= 1\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "     * Function to detect outliers on one-dimentional datasets\n",
    "    \"\"\"\n",
    "    def execute(self, series):\n",
    "        outliers = []\n",
    "        \n",
    "        if not self.checkAllElementsEqual(series):          \n",
    "            df = pd.DataFrame({'temp':series})\n",
    "            clf = IsolationForest().fit(df['temp'].values.reshape(-1, 1)) \n",
    "            outliersInds = clf.predict(df['temp'].values.reshape(-1, 1))\n",
    "            \n",
    "            for indx in range(0, len(outliersInds)):\n",
    "                if outliersInds[indx] == -1:\n",
    "                    outliers.append(series[indx])    \n",
    "                    \n",
    "        return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a571e849",
   "metadata": {},
   "source": [
    "### Execution of Isolation Forest Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37b5a2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 60, 63, 63, 64, 65, 72.5126, 75.671004, 76.813091, 77.141509, 79.782605, 87.640727, 88.050064, 136.782077, 146.902942, 156.476319, 159.2281, 164.957759, 167.574109, 169.114286, 169.429444, 172.353, 197.4606]\n"
     ]
    }
   ],
   "source": [
    "isolationForest = IsolationForestMethod()\n",
    "\n",
    "outliers_isolation_forest = isolationForest.execute(series)\n",
    "\n",
    "print(outliers_isolation_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a3f0df",
   "metadata": {},
   "source": [
    "## Calculate the Joint Result of the Three Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7faabc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCommonOutliers(outliers_1, outliers_2, outliers_3):\n",
    "    # converting the arrays into sets\n",
    "    set_outliers_1 = set(outliers_1)\n",
    "    set_outliers_2 = set(outliers_2)\n",
    "    set_outliers_3 = set(outliers_3)\n",
    "      \n",
    "    # calculates intersection of sets on set_outliers_1 and set_outliers_2\n",
    "    set_intersec_1 = set_outliers_1.intersection(set_outliers_2)       \n",
    "      \n",
    "    # calculates intersection of sets on set1 and s3\n",
    "    result_set = set_intersec_1.intersection(set_outliers_3)\n",
    "      \n",
    "    # converts resulting set to list\n",
    "    final_list = list(result_set)\n",
    "    \n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e24c0367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 197.4606]\n"
     ]
    }
   ],
   "source": [
    "joint_result = findCommonOutliers(outliers_dixon_q, outliers_standard_deviation, outliers_isolation_forest)\n",
    "print(joint_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2330fec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
